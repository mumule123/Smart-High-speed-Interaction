#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®¾å¤‡æ“ä½œæ£€æµ‹ç³»ç»Ÿ - ç®€åŒ–ç‰ˆæœ¬
ä½¿ç”¨å›ºå®šåæ ‡è€Œä¸è¿›è¡Œè®¾å¤‡è¯†åˆ«ï¼Œç»“åˆäººä½“å§¿æ€è¯†åˆ«åˆ†ææ“ä½œè¡Œä¸º
"""

import os
import cv2
import numpy as np
import pandas as pd
from ultralytics import YOLO
import argparse
from collections import defaultdict
import json  # ç”¨äºåŠ è½½object.jsonå’Œä¿å­˜åˆ†ææŠ¥å‘Š
from datetime import datetime
import math
from PIL import Image, ImageDraw, ImageFont

# å¯¼å…¥é…ç½®ç®¡ç†å™¨
from config_manager import ConfigManager


class OperationDetector:
    def __init__(self, project_root, config_file_path):
        """
        åˆå§‹åŒ–æ“ä½œæ£€æµ‹å™¨
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
            config_file_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.project_root = project_root
        
        # åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆä½¿ç”¨é…ç½®ç®¡ç†å™¨ï¼‰
        config_manager = ConfigManager()
        self.config = config_manager.load_config(config_file_path)
        
        # è®¾å¤‡ç±»åˆ«æ˜ å°„ï¼ˆä»é…ç½®ä¸­è·å–ï¼‰
        self.all_classes = self.config['all_classes']
        
        # æ“ä½œåˆ¤æ–­é˜ˆå€¼ï¼ˆåƒç´ è·ç¦»ï¼Œä»é…ç½®æ–‡ä»¶è·å–ï¼‰
        self.operation_threshold = self.config['thresholds']['operation_distance_threshold']
        
        # åŠ è½½æ¨¡å‹ï¼ˆåªåŠ è½½å§¿æ€è¯†åˆ«æ¨¡å‹ï¼Œä¸åŠ è½½ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼‰
        self.load_models()
        
        # æ“ä½œè®°å½•
        self.operation_records = defaultdict(list)
        
        # çŠ¶æ€è·Ÿè¸ªï¼šè®°å½•æ¯ä¸ªäººå‘˜å¯¹æ¯ä¸ªè®¾å¤‡çš„æ“ä½œçŠ¶æ€å’Œæ—¶é—´
        self.operation_states = defaultdict(lambda: defaultdict(dict))  # person_id -> device_id -> state_info
        
        # æ—¶é—´é˜ˆå€¼é…ç½®
        self.operation_start_time = 3.0  # è¿‘è·ç¦»è¶…è¿‡3ç§’æ‰ç®—æ­£åœ¨æ“ä½œ
        self.operation_end_time = 2.0    # è¿œç¦»è¶…è¿‡2ç§’æ‰ç®—ç»“æŸæ“ä½œ
        
        # åŠ è½½è®¾å¤‡å¤šè¾¹å½¢æ•°æ®
        self.device_polygons = self.load_device_polygons_from_json()
        
        # åŠ è½½ä¸­æ–‡å­—ä½“
        self.load_chinese_font()
    
    def load_device_polygons_from_json(self):
        """
        ä»object.jsonæ–‡ä»¶åŠ è½½è®¾å¤‡å¤šè¾¹å½¢æ•°æ®
        è¿”å›è®¾å¤‡åç§°åˆ°å¤šè¾¹å½¢ä¿¡æ¯çš„æ˜ å°„
        """
        json_file_path = os.path.join(self.project_root, 'datasets', 'object.json')
        device_polygons = {}
        
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # è§£æJSONæ•°æ®ç»“æ„
            if isinstance(data, list) and len(data) > 0:
                annotations = data[0].get('annotations', [])
                
                for annotation in annotations:
                    result = annotation.get('result', [])
                    
                    for item in result:
                        if item.get('type') == 'polygonlabels':
                            value = item.get('value', {})
                            points = value.get('points', [])
                            labels = value.get('polygonlabels', [])
                            
                            if points and labels:
                                device_name = labels[0]  # å–ç¬¬ä¸€ä¸ªæ ‡ç­¾ä½œä¸ºè®¾å¤‡åç§°
                                
                                # åæ ‡æ˜¯ç™¾åˆ†æ¯”å½¢å¼ï¼Œéœ€è¦ä¿å­˜åŸå§‹æ•°æ®
                                device_polygons[device_name] = {
                                    'points_percent': points,
                                    'original_width': item.get('original_width', 1920),
                                    'original_height': item.get('original_height', 1080),
                                    'id': item.get('id', '')
                                }
            
            print(f"âœ“ ä»object.jsonåŠ è½½äº† {len(device_polygons)} ä¸ªè®¾å¤‡å¤šè¾¹å½¢")
            for device_name in device_polygons.keys():
                print(f"  - {device_name}")
                
        except Exception as e:
            print(f"è­¦å‘Š: åŠ è½½object.jsonå¤±è´¥ {e}")
            
        return device_polygons
    
    def convert_polygon_to_pixels(self, points_percent, img_width, img_height):
        """
        å°†ç™¾åˆ†æ¯”åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡
        Args:
            points_percent: ç™¾åˆ†æ¯”åæ ‡ç‚¹åˆ—è¡¨ [[x1, y1], [x2, y2], ...]
            img_width: å›¾åƒå®½åº¦
            img_height: å›¾åƒé«˜åº¦
        Returns:
            åƒç´ åæ ‡ç‚¹åˆ—è¡¨
        """
        pixel_points = []
        for point in points_percent:
            x_pixel = int(point[0] * img_width / 100.0)
            y_pixel = int(point[1] * img_height / 100.0)
            pixel_points.append([x_pixel, y_pixel])
        return pixel_points
    
    def calculate_point_to_polygon_distance(self, point, polygon_points):
        """
        è®¡ç®—ç‚¹åˆ°å¤šè¾¹å½¢è¾¹ç•Œçš„è·ç¦» - ä½¿ç”¨OpenCVå®ç°
        Args:
            point: ç‚¹åæ ‡ {'x': x, 'y': y}
            polygon_points: å¤šè¾¹å½¢åƒç´ åæ ‡ç‚¹åˆ—è¡¨
        Returns:
            float: åˆ°å¤šè¾¹å½¢è¾¹ç•Œçš„è·ç¦»ï¼ˆåƒç´ ï¼‰ï¼Œå¦‚æœåœ¨å†…éƒ¨è¿”å›0
        """
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„æ ¼å¼
            test_point = (point['x'], point['y'])
            polygon_array = np.array(polygon_points, dtype=np.int32)
            
            # æ£€æŸ¥ç‚¹åˆ°å¤šè¾¹å½¢çš„è·ç¦»
            result = cv2.pointPolygonTest(polygon_array, test_point, True)
            
            # result > 0: ç‚¹åœ¨å¤šè¾¹å½¢å†…éƒ¨ï¼Œè·ç¦»ä¸ºæ­£å€¼
            # result = 0: ç‚¹åœ¨å¤šè¾¹å½¢è¾¹ç•Œä¸Š  
            # result < 0: ç‚¹åœ¨å¤šè¾¹å½¢å¤–éƒ¨ï¼Œç»å¯¹å€¼æ˜¯åˆ°è¾¹ç•Œçš„è·ç¦»
            
            if result >= 0:  # åœ¨å†…éƒ¨æˆ–è¾¹ç•Œä¸Š
                return 0.0  # åœ¨å†…éƒ¨æˆ–è¾¹ç•Œä¸Šï¼Œè§†ä¸ºè·ç¦»ä¸º0
            else:
                return abs(result)  # åœ¨å¤–éƒ¨ï¼Œè¿”å›åˆ°è¾¹ç•Œçš„è·ç¦»
            
        except Exception as e:
            print(f"è­¦å‘Š: è®¡ç®—ç‚¹åˆ°å¤šè¾¹å½¢è·ç¦»å¤±è´¥ {e}")
            return float('inf')
    
    
    def load_chinese_font(self):
        """åŠ è½½ä¸­æ–‡å­—ä½“"""
        try:
            # ä¸­æ–‡å­—ä½“è·¯å¾„
            font_path = os.path.join(self.project_root, self.config['font_settings']['chinese_font_path'])
            if os.path.exists(font_path):
                font_size_normal = self.config['font_settings']['font_size_normal']
                font_size_small = self.config['font_settings']['font_size_small']
                self.chinese_font = ImageFont.truetype(font_path, font_size_normal)
                self.chinese_font_small = ImageFont.truetype(font_path, font_size_small)
                print(f"âœ“ ä¸­æ–‡å­—ä½“åŠ è½½æˆåŠŸ: {font_path}")
            else:
                print(f"è­¦å‘Š: ä¸­æ–‡å­—ä½“æ–‡ä»¶ä¸å­˜åœ¨: {font_path}")
                self.chinese_font = ImageFont.load_default()
                self.chinese_font_small = ImageFont.load_default()
        except Exception as e:
            print(f"è­¦å‘Š: ä¸­æ–‡å­—ä½“åŠ è½½å¤±è´¥ {e}, ä½¿ç”¨é»˜è®¤å­—ä½“")
            self.chinese_font = ImageFont.load_default()
            self.chinese_font_small = ImageFont.load_default()
    
    def draw_chinese_text(self, image, text, position, font, color=(255, 255, 255)):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬
        Args:
            image: OpenCVå›¾åƒ (BGRæ ¼å¼)
            text: è¦ç»˜åˆ¶çš„æ–‡æœ¬
            position: æ–‡æœ¬ä½ç½® (x, y)
            font: PILå­—ä½“å¯¹è±¡
            color: æ–‡æœ¬é¢œè‰² (B, G, R)
        Returns:
            ç»˜åˆ¶äº†æ–‡æœ¬çš„å›¾åƒ
        """
        # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPILå›¾åƒ
        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)
        
        # ç»˜åˆ¶æ–‡æœ¬ (PILä½¿ç”¨RGBæ ¼å¼)
        rgb_color = (color[2], color[1], color[0])  # BGRè½¬RGB
        draw.text(position, text, font=font, fill=rgb_color)
        
        # è½¬æ¢å›OpenCVæ ¼å¼
        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
    def load_models(self):
        try:
            # åŠ è½½å§¿æ€è¯†åˆ«æ¨¡å‹
            pose_model_path = os.path.join(self.project_root, self.config['models']['pose_model_path'])
            self.pose_model = YOLO(pose_model_path)
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def get_hand_keypoints(self, keypoints):
        """
        ä»YOLO poseæ£€æµ‹ç»“æœä¸­æå–æ‰‹éƒ¨å…³é”®ç‚¹
        è¿”å›å·¦å³æ‰‹è…•çš„åæ ‡
        """
        # YOLO poseå…³é”®ç‚¹ç´¢å¼•ï¼ˆCOCOæ ¼å¼ï¼‰- ä»é…ç½®ä¸­è·å–
        keypoint_indices = self.config['keypoint_indices']
        
        hand_points = {}
        
        for point_name, index in keypoint_indices.items():
            if index < len(keypoints):
                x, y, confidence = keypoints[index]
                # ä½¿ç”¨é…ç½®ä¸­çš„ç½®ä¿¡åº¦é˜ˆå€¼
                keypoint_threshold = self.config['thresholds']['keypoint_confidence_threshold']
                if confidence > keypoint_threshold:
                    hand_points[point_name] = {'x': float(x), 'y': float(y), 'confidence': float(confidence)}
                else:
                    hand_points[point_name] = {'x': None, 'y': None, 'confidence': float(confidence)}
            else:
                hand_points[point_name] = {'x': None, 'y': None, 'confidence': 0.0}
        
        return hand_points
    
    def calculate_weighted_hand_center(self, hand_points):
        """
        ä½¿ç”¨åŠ æƒå…¬å¼è®¡ç®—æ‰‹éƒ¨ä¸­å¿ƒç‚¹
        å…¬å¼: ä¸­å¿ƒç‚¹ä½ç½® = 0.5*left_wrist + 0.5*right_wrist
        """
        left_wrist = hand_points['left_wrist']
        right_wrist = hand_points['right_wrist']
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æœ‰æ•ˆç‚¹æ¥è®¡ç®—ä¸­å¿ƒç‚¹
        valid_points = []
        weights = []
        
        # ä»é…ç½®æ–‡ä»¶è·å–æƒé‡
        weights_config = self.config['hand_center_weights']
        
        if left_wrist['x'] is not None and left_wrist['y'] is not None:
            valid_points.append((left_wrist['x'], left_wrist['y']))
            weights.append(weights_config['left_wrist_weight'])
            
        if right_wrist['x'] is not None and right_wrist['y'] is not None:
            valid_points.append((right_wrist['x'], right_wrist['y']))
            weights.append(weights_config['right_wrist_weight'])
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç‚¹ï¼Œè¿”å›None
        if len(valid_points) == 0:
            return {'x': None, 'y': None}
        
        # æ ¹æ®æœ‰æ•ˆç‚¹é‡æ–°è®¡ç®—æƒé‡ï¼ˆç¡®ä¿æƒé‡å’Œä¸º1ï¼‰
        total_weight = sum(weights)
        normalized_weights = [w / total_weight for w in weights]
        
        # è®¡ç®—åŠ æƒä¸­å¿ƒç‚¹
        center_x = sum(p[0] * w for p, w in zip(valid_points, normalized_weights))
        center_y = sum(p[1] * w for p, w in zip(valid_points, normalized_weights))
        
        return {'x': float(center_x), 'y': float(center_y)}
    
    
    
    def calculate_center_point(self, points):
        """è®¡ç®—å¤šä¸ªç‚¹çš„ä¸­å¿ƒä½ç½®ï¼Œæ”¯æŒåˆ—è¡¨æˆ–å­—å…¸è¾“å…¥"""
        # å¦‚æœæ˜¯å­—å…¸ï¼ˆå¦‚ hand_pointsï¼‰ï¼Œå–å…¶ values
        if isinstance(points, dict):
            points = list(points.values())
        valid_points = []
        for point in points:
            if isinstance(point, dict) and point.get('x') is not None and point.get('y') is not None:
                valid_points.append((point['x'], point['y']))
        if len(valid_points) == 0:
            return {'x': None, 'y': None}
        center_x = sum(p[0] for p in valid_points) / len(valid_points)
        center_y = sum(p[1] for p in valid_points) / len(valid_points)
        return {'x': float(center_x), 'y': float(center_y)}
    
    
    
    
    def detect_objects(self, frame, frame_number=0, timestamp=0.0):
        """
        ä½¿ç”¨object.jsonä¸­çš„å¤šè¾¹å½¢æ•°æ®ä½œä¸ºè®¾å¤‡ä½ç½®
        
        Args:
            frame: è¾“å…¥å›¾åƒå¸§
            frame_number: å½“å‰å¸§å·
            timestamp: å½“å‰æ—¶é—´æˆ³(ç§’)ï¼ˆç”¨äºç¼“å­˜ç®¡ç†ï¼‰
            
        Returns:
            list: æ£€æµ‹åˆ°çš„è®¾å¤‡åˆ—è¡¨
        """
        detected_objects = []
        
        # è·å–å›¾åƒå°ºå¯¸
        img_height, img_width = frame.shape[:2]
        
        # ä½¿ç”¨å›ºå®šåæ ‡ç½®ä¿¡åº¦
        fixed_confidence = self.config['thresholds']['fixed_coordinate_confidence']
        
        print(f"ğŸ” å¸§ {frame_number}: ä½¿ç”¨å¤šè¾¹å½¢æ•°æ®åŠ è½½è®¾å¤‡")
        
        # å¤„ç†æ¯ä¸ªè®¾å¤‡çš„å¤šè¾¹å½¢æ•°æ®
        device_id = 0  # åˆ†é…è®¾å¤‡ID
        for device_name, polygon_data in self.device_polygons.items():
            # å°†ç™¾åˆ†æ¯”åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡
            pixel_points = self.convert_polygon_to_pixels(
                polygon_data['points_percent'], img_width, img_height
            )
            
            # è®¡ç®—å¤šè¾¹å½¢çš„ä¸­å¿ƒç‚¹ï¼ˆè´¨å¿ƒï¼‰
            center_x = sum(p[0] for p in pixel_points) / len(pixel_points)
            center_y = sum(p[1] for p in pixel_points) / len(pixel_points)
            
            # è®¡ç®—è¾¹ç•Œæ¡†
            min_x = min(p[0] for p in pixel_points)
            max_x = max(p[0] for p in pixel_points)
            min_y = min(p[1] for p in pixel_points)
            max_y = max(p[1] for p in pixel_points)
            
            detected_objects.append({
                'class_id': device_id,
                'class_name': device_name,
                'center': {'x': float(center_x), 'y': float(center_y)},
                'bbox': [min_x, min_y, max_x, max_y],
                'confidence': fixed_confidence,
                'polygon_points': pixel_points,  # æ·»åŠ å¤šè¾¹å½¢ç‚¹
                'source': 'json_polygons'  # æ ‡è®°æ¥æºä¸ºJSONå¤šè¾¹å½¢
            })
            
            device_id += 1
        
        print(f"âœ“ å¸§ {frame_number}: å¤šè¾¹å½¢æ¨¡å¼åŠ è½½äº† {len(detected_objects)} ä¸ªè®¾å¤‡")
        
        return detected_objects
    
    def detect_poses(self, frame):
        """ä½¿ç”¨å§¿æ€è¯†åˆ«æ¨¡å‹æ£€æµ‹äººä½“å§¿æ€"""
        results = self.pose_model(frame)
        detected_persons = []
        
        for r in results:
            if r.keypoints is not None:
                for i, keypoints in enumerate(r.keypoints.data):
                    # æå–æ‰‹éƒ¨å…³é”®ç‚¹
                    hand_points = self.get_hand_keypoints(keypoints)
                    
                    # ä½¿ç”¨åŠ æƒå…¬å¼è®¡ç®—æ‰‹éƒ¨ä¸­å¿ƒç‚¹
                    # å…¬å¼å‚æ•°ä»é…ç½®æ–‡ä»¶è·å–  2é’Ÿé€‰æ‹©ï¼Œä½¿ç”¨åŠ æƒæˆ–è€…ç›´æ¥å¹³å‡
                    hand_center = self.calculate_center_point(hand_points)
                    
                    if hand_center['x'] is not None:  # åªæœ‰å½“èƒ½è®¡ç®—å‡ºæ‰‹éƒ¨ä¸­å¿ƒæ—¶æ‰æ·»åŠ 
                        detected_persons.append({
                            'person_id': i,
                            'hand_keypoints': hand_points,
                            'hand_center': hand_center
                        })
        
        return detected_persons
    
    def analyze_operations(self, persons, objects, frame_number, timestamp):
        """åˆ†æäººå‘˜æ“ä½œè¡Œä¸º - ä½¿ç”¨å¤šè¾¹å½¢è·ç¦»åˆ¤æ–­å’Œæ—¶é—´çŠ¶æ€ç®¡ç†"""
        operations = []
        operation_threshold = 60  # å›ºå®šä½¿ç”¨60åƒç´ ä½œä¸ºæ“ä½œåˆ¤æ–­é˜ˆå€¼
        
        for person in persons:
            if person['hand_center']['x'] is None:
                continue
            
            person_id = person['person_id']
            
            # å­˜å‚¨å½“å‰äººå‘˜å¯¹æ‰€æœ‰è®¾å¤‡çš„å€™é€‰æ“ä½œ
            candidate_operations = []
            
            # æ£€æŸ¥æ¯ä¸ªè®¾å¤‡çš„å¤šè¾¹å½¢
            for obj in objects:
                device_id = obj['class_id']
                device_name = obj['class_name']
                
                # æ£€æŸ¥æ‰‹éƒ¨åˆ°å¤šè¾¹å½¢è¾¹ç•Œçš„è·ç¦»
                if 'polygon_points' in obj and obj['polygon_points']:
                    distance_to_polygon = self.calculate_point_to_polygon_distance(
                        person['hand_center'], 
                        obj['polygon_points']
                    )
                    
                    # åªæœ‰å½“è·ç¦»å°äº60åƒç´ æ—¶æ‰è¿›è¡Œåç»­å¤„ç†
                    if distance_to_polygon > operation_threshold:
                        # è·ç¦»å¤§äº60åƒç´ ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®çŠ¶æ€
                        if device_id in self.operation_states[person_id]:
                            state_info = self.operation_states[person_id][device_id]
                            if state_info['status'] in ['near', 'operating']:
                                if state_info['far_start_time'] is None:
                                    # åˆšå¼€å§‹è¿œç¦»
                                    state_info['far_start_time'] = timestamp
                                elif timestamp - state_info['far_start_time'] >= self.operation_end_time:
                                    # è¿œç¦»æ—¶é—´è¶…è¿‡2ç§’ï¼Œç»“æŸæ“ä½œ
                                    state_info['status'] = 'far'
                                    state_info['near_start_time'] = None
                                    state_info['operating_start_time'] = None
                                    state_info['far_start_time'] = None
                        continue  # è·³è¿‡è¿™ä¸ªè®¾å¤‡ï¼Œä¸è¿›è¡Œåç»­è®¡ç®—å’Œè®°å½•
                    
                    # è·ç¦»å°äºç­‰äº60åƒç´ ï¼Œåˆå§‹åŒ–çŠ¶æ€ä¿¡æ¯ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    if device_id not in self.operation_states[person_id]:
                        self.operation_states[person_id][device_id] = {
                            'status': 'far',  # çŠ¶æ€ï¼šfar/near/operating
                            'near_start_time': None,  # å¼€å§‹æ¥è¿‘çš„æ—¶é—´
                            'operating_start_time': None,  # å¼€å§‹æ“ä½œçš„æ—¶é—´
                            'far_start_time': None,  # å¼€å§‹è¿œç¦»çš„æ—¶é—´
                            'last_distance': float('inf')
                        }
                    
                    state_info = self.operation_states[person_id][device_id]
                    
                    # åŸºäºè·ç¦»æ›´æ–°çŠ¶æ€ï¼ˆåªåœ¨è·ç¦»<=60æ—¶æ‰§è¡Œï¼‰
                    if distance_to_polygon <= operation_threshold:
                        # åœ¨æ“ä½œèŒƒå›´å†…
                        if state_info['status'] == 'far':
                            # ä»è¿œç¦»çŠ¶æ€è½¬ä¸ºæ¥è¿‘çŠ¶æ€
                            state_info['status'] = 'near'
                            state_info['near_start_time'] = timestamp
                            state_info['far_start_time'] = None
                        elif state_info['status'] == 'near':
                            # æ£€æŸ¥æ˜¯å¦æ¥è¿‘æ—¶é—´è¶…è¿‡3ç§’
                            if timestamp - state_info['near_start_time'] >= self.operation_start_time:
                                state_info['status'] = 'operating'
                                state_info['operating_start_time'] = timestamp
                        # å¦‚æœå·²ç»åœ¨æ“ä½œçŠ¶æ€ï¼Œä¿æŒçŠ¶æ€ä¸å˜
                    
                    state_info['last_distance'] = distance_to_polygon
                    
                    # æ ¹æ®å½“å‰çŠ¶æ€å†³å®šæ˜¯å¦æ·»åŠ åˆ°å€™é€‰æ“ä½œåˆ—è¡¨
                    if state_info['status'] in ['near', 'operating']:
                        candidate_operation = {
                            'frame_number': frame_number,
                            'timestamp': timestamp,
                            'person_id': person['person_id'],
                            'device_class_id': obj['class_id'],
                            'device_name': obj['class_name'],
                            'distance': distance_to_polygon,
                            'hand_center': person['hand_center'],
                            'device_center': obj['center'],
                            'device_confidence': obj['confidence'],
                            'operation_status': state_info['status'],  # æ·»åŠ æ“ä½œçŠ¶æ€
                            'near_duration': timestamp - state_info['near_start_time'] if state_info['near_start_time'] else 0,
                            'operating_duration': timestamp - state_info['operating_start_time'] if state_info['operating_start_time'] else 0,
                            'operation_type': 'time_based_polygon_detection'
                        }
                        candidate_operations.append(candidate_operation)
            
            # æ¯ä¸€å¸§æ¯ä¸ªäººåªèƒ½å¯¹ä¸€ä¸ªè®¾å¤‡è¿›è¡Œäº¤äº’ï¼Œé€‰æ‹©è·ç¦»æœ€è¿‘çš„è®¾å¤‡
            if candidate_operations:
                # ä¼˜å…ˆé€‰æ‹©æ­£åœ¨æ“ä½œçŠ¶æ€çš„è®¾å¤‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™é€‰æ‹©è·ç¦»æœ€è¿‘çš„æ¥è¿‘çŠ¶æ€è®¾å¤‡
                operating_ops = [op for op in candidate_operations if op['operation_status'] == 'operating']
                if operating_ops:
                    best_operation = min(operating_ops, key=lambda op: op['distance'])
                else:
                    best_operation = min(candidate_operations, key=lambda op: op['distance'])
                
                operations.append(best_operation)
                
                # åªæœ‰æ­£åœ¨æ“ä½œçŠ¶æ€çš„æ‰è®°å½•åˆ°æ“ä½œå†å²
                if best_operation['operation_status'] == 'operating':
                    self.operation_records[best_operation['device_class_id']].append(best_operation)
                
                # æ‰“å°çŠ¶æ€ä¿¡æ¯
                status_text = {
                    'near': f"åœ¨{best_operation['device_name']}æ— (æ¥è¿‘{best_operation['near_duration']:.1f}s)",
                    'operating': f"æ­£åœ¨æ“ä½œ{best_operation['device_name']} (æ“ä½œ{best_operation['operating_duration']:.1f}s)"
                }
                print(f"å¸§ {frame_number}: äººå‘˜ {person['person_id']} {status_text.get(best_operation['operation_status'], 'æœªçŸ¥çŠ¶æ€')} (è·ç¦»: {best_operation['distance']:.1f}px)")
        
        return operations
    
    def draw_annotations(self, frame, objects, persons, operations):
        """åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœå’Œæ“ä½œåˆ†æ"""
        annotated_frame = frame.copy()
        
        # ç»˜åˆ¶æ£€æµ‹åˆ°çš„è®¾å¤‡å¤šè¾¹å½¢
        for obj in objects:
            center_x, center_y = int(obj['center']['x']), int(obj['center']['y'])
            
            # ç»˜åˆ¶å¤šè¾¹å½¢ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'polygon_points' in obj and obj['polygon_points']:
                polygon_points = np.array(obj['polygon_points'], dtype=np.int32)
                
                # ç»˜åˆ¶å¤šè¾¹å½¢è¾¹æ¡†
                polygon_color = (0, 255, 0)  # ç»¿è‰²è¾¹æ¡†
                cv2.polylines(annotated_frame, [polygon_points], True, polygon_color, 2)
                
                # ç»˜åˆ¶åŠé€æ˜å¤šè¾¹å½¢å¡«å……
                overlay = annotated_frame.copy()
                cv2.fillPoly(overlay, [polygon_points], (0, 255, 0))  # ç»¿è‰²å¡«å……
                annotated_frame = cv2.addWeighted(annotated_frame, 0.8, overlay, 0.2, 0)
                
                # åœ¨å¤šè¾¹å½¢ä¸Šæ ‡æ³¨è®¾å¤‡åç§°
                annotated_frame = self.draw_chinese_text(
                    annotated_frame, obj['class_name'], 
                    (center_x - 30, center_y - 10), 
                    self.chinese_font_small, 
                    (255, 255, 255)
                )
            
            # è®¾å¤‡ä¸­å¿ƒç‚¹é¢œè‰²å’ŒåŠå¾„ä»é…ç½®è·å–
            center_color = tuple(self.config['visualization']['device_center_color'])
            center_radius = self.config['visualization']['device_center_radius']
            
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(annotated_frame, (center_x, center_y), center_radius, center_color, -1)
        
        # ç»˜åˆ¶äººä½“æ‰‹éƒ¨å…³é”®ç‚¹
        hand_colors = self.config['hand_colors']
        keypoint_radius = self.config['visualization']['keypoint_radius']
        
        for person in persons:
            # ç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹
            for point_name, point_data in person['hand_keypoints'].items():
                if point_data['x'] is not None and point_data['y'] is not None:
                    x, y = int(point_data['x']), int(point_data['y'])
                    color = tuple(hand_colors.get(point_name, [255, 255, 255]))
                    cv2.circle(annotated_frame, (x, y), keypoint_radius, color, -1)
                    cv2.putText(annotated_frame, point_name[:5], (x+8, y-8), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
            
            # ç»˜åˆ¶æ‰‹éƒ¨ä¸­å¿ƒç‚¹
            if person['hand_center']['x'] is not None:
                center_x = int(person['hand_center']['x'])
                center_y = int(person['hand_center']['y'])
                hand_center_color = tuple(self.config['visualization']['hand_center_color'])
                hand_center_radius = self.config['visualization']['hand_center_radius']
                cv2.circle(annotated_frame, (center_x, center_y), hand_center_radius, hand_center_color, -1)  # çº¢è‰²
                cv2.putText(annotated_frame, f'P{person["person_id"]}', (center_x+12, center_y-12), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        # ç»˜åˆ¶æ“ä½œè¿çº¿å’Œæ ‡æ³¨
        for op in operations:
            hand_x = int(op['hand_center']['x'])
            hand_y = int(op['hand_center']['y'])
            device_x = int(op['device_center']['x'])
            device_y = int(op['device_center']['y'])
            
            # æ ¹æ®æ“ä½œçŠ¶æ€é€‰æ‹©ä¸åŒçš„é¢œè‰²å’Œæ ·å¼
            operation_status = op.get('operation_status', 'near')
            
            if operation_status == 'operating':
                # æ­£åœ¨æ“ä½œçŠ¶æ€ï¼šçº¢è‰²ç²—çº¿
                line_color = (0, 0, 255)  # çº¢è‰²
                line_thickness = 3
                text_color = (0, 0, 255)  # çº¢è‰²æ–‡å­—
                operation_text = f"æ­£åœ¨æ“ä½œ: {op['device_name']}"
                duration_text = f"æ“ä½œæ—¶é•¿: {op.get('operating_duration', 0):.1f}ç§’"
            else:
                # æ¥è¿‘çŠ¶æ€ï¼šæ©™è‰²ç»†çº¿
                line_color = (0, 165, 255)  # æ©™è‰²
                line_thickness = 2
                text_color = (0, 165, 255)  # æ©™è‰²æ–‡å­—
                operation_text = f"åœ¨è®¾å¤‡æ—: {op['device_name']}"
                duration_text = f"æ¥è¿‘æ—¶é•¿: {op.get('near_duration', 0):.1f}ç§’"
            
            # ç»˜åˆ¶è¿çº¿
            cv2.line(annotated_frame, (hand_x, hand_y), (device_x, device_y), line_color, line_thickness)
            
            # æ ‡æ³¨æ“ä½œä¿¡æ¯ï¼ˆä½¿ç”¨ä¸­æ–‡å­—ä½“ï¼‰
            mid_x = (hand_x + device_x) // 2
            mid_y = (hand_y + device_y) // 2
            
            # æ˜¾ç¤ºåˆ°å¤šè¾¹å½¢è¾¹ç•Œçš„è·ç¦»
            if op['distance'] == 0.0:
                distance_text = f"è¾¹ç•Œè·ç¦»: å†…éƒ¨/è¾¹ç•Œä¸Š"
            else:
                distance_text = f"è¾¹ç•Œè·ç¦»: {op['distance']:.1f}px"
            
            # ä½¿ç”¨ä¸­æ–‡å­—ä½“ç»˜åˆ¶æ“ä½œä¿¡æ¯
            annotated_frame = self.draw_chinese_text(
                annotated_frame, operation_text, (mid_x, mid_y-35), self.chinese_font_small, text_color
            )
            annotated_frame = self.draw_chinese_text(
                annotated_frame, duration_text, (mid_x, mid_y-15), self.chinese_font_small, text_color
            )
            annotated_frame = self.draw_chinese_text(
                annotated_frame, distance_text, (mid_x, mid_y+5), self.chinese_font_small, text_color
            )
        
        return annotated_frame
    
    def process_video(self, video_path, output_dir):
        """å¤„ç†è§†é¢‘æ–‡ä»¶"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        
        print(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps} FPS, å…± {total_frames} å¸§")
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        output_video_path = os.path.join(output_dir, 'operation_analysis.mp4')
        out_video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
        
        # æ•°æ®è®°å½•
        all_frame_data = []
        frame_count = 0
        processed_count = 0  # å®é™…å¤„ç†çš„å¸§æ•°
        
        # ç¼“å­˜æœ€åä¸€æ¬¡çš„æ£€æµ‹ç»“æœï¼Œç”¨äºè·³å¸§æ—¶ç»§ç»­æ˜¾ç¤ºæ ‡æ³¨
        last_detected_objects = []
        last_detected_persons = []
        last_operations = []
        
        # è®¡ç®—å¸§é—´éš”ï¼šæ¯ç§’10å¸§ = fps/10 å¸§é—´éš”
        frame_interval = max(1, fps // 10)  # ç¡®ä¿è‡³å°‘ä¸º1
        print(f"æ£€æµ‹è®¾ç½®: æ¯ç§’æ£€æµ‹3å¸§ (æ¯ {frame_interval} å¸§æ£€æµ‹ä¸€æ¬¡)")
        print(f"æ ‡æ³¨æ˜¾ç¤º: æ‰€æœ‰å¸§éƒ½æ˜¾ç¤ºæ ‡æ³¨ (ä½¿ç”¨æœ€æ–°æ£€æµ‹ç»“æœ)")
        
        print("å¼€å§‹å¤„ç†è§†é¢‘...")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            timestamp = frame_count / fps
            
            if frame_count % 300 == 0:  # æ¯300å¸§æ˜¾ç¤ºè¿›åº¦
                print(f"å¤„ç†è¿›åº¦: {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%) - å·²æ£€æµ‹ {processed_count} å¸§")
            
            # åªåœ¨æŒ‡å®šé—´éš”çš„å¸§ä¸Šè¿›è¡Œæ£€æµ‹å’Œåˆ†æ
            if (frame_count - 1) % frame_interval == 0:
                processed_count += 1
                
                # æ£€æµ‹ç‰©ä½“å’Œäººä½“å§¿æ€
                detected_objects = self.detect_objects(frame, frame_count, timestamp)
                detected_persons = self.detect_poses(frame)
                
                # åˆ†ææ“ä½œè¡Œä¸º
                operations = self.analyze_operations(detected_persons, detected_objects, frame_count, timestamp)
                
                # ç¼“å­˜å½“å‰æ£€æµ‹ç»“æœ
                last_detected_objects = detected_objects
                last_detected_persons = detected_persons
                last_operations = operations
                
                # ç»˜åˆ¶æ ‡æ³¨
                annotated_frame = self.draw_annotations(frame, detected_objects, detected_persons, operations)
            else:
                # è·³è¿‡çš„å¸§ä½¿ç”¨ç¼“å­˜çš„æ£€æµ‹ç»“æœæ¥ç»˜åˆ¶æ ‡æ³¨ï¼Œä¿æŒæ ‡æ³¨è¿ç»­æ˜¾ç¤º
                if last_detected_objects and last_detected_persons:
                    annotated_frame = self.draw_annotations(frame, last_detected_objects, last_detected_persons, last_operations)
                else:
                    # å¦‚æœè¿˜æ²¡æœ‰ç¼“å­˜ç»“æœï¼Œä½¿ç”¨åŸå¸§
                    annotated_frame = frame
            
            # å†™å…¥è§†é¢‘
            out_video.write(annotated_frame)
        
        cap.release()
        out_video.release()
        
        print(f"è§†é¢‘å¤„ç†å®Œæˆï¼å…± {frame_count} å¸§ï¼Œå®é™…æ£€æµ‹ {processed_count} å¸§ (æ¯ç§’3å¸§)")
        print(f"æ£€æµ‹æ•ˆç‡æå‡: {frame_count/processed_count:.1f}x é€Ÿåº¦")
        print(f"æ ‡æ³¨æ˜¾ç¤º: æ‰€æœ‰å¸§éƒ½æœ‰è¿ç»­æ ‡æ³¨æ˜¾ç¤º")
        print(f"æ ‡æ³¨è§†é¢‘ä¿å­˜ä¸º: {output_video_path}")
        
        return all_frame_data
    
def main():
    """ä¸»å‡½æ•°"""
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    
    # é»˜è®¤YAMLé…ç½®æ–‡ä»¶è·¯å¾„
    default_config_path = os.path.join(project_root, 'config.yaml')
    
    parser = argparse.ArgumentParser(description='è®¾å¤‡æ“ä½œæ£€æµ‹åˆ†æç³»ç»Ÿ V3')
    parser.add_argument('--config', type=str, default=default_config_path,
                       help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)')
    parser.add_argument('--video', type=str, default=None,
                       help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„ (å¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®)')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºç»“æœç›®å½•è·¯å¾„ (å¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®)')
    parser.add_argument('--threshold', type=float, default=None,
                       help='æ“ä½œåˆ¤æ–­è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰ (å¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.config):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        return
    
    try:
        # åˆå§‹åŒ–æ£€æµ‹å™¨ï¼Œä¼ å…¥é…ç½®æ–‡ä»¶è·¯å¾„
        detector = OperationDetector(project_root, args.config)
        
        # ä»é…ç½®æ–‡ä»¶è·å–é»˜è®¤å‚æ•°ï¼Œæˆ–ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
        video_path = args.video if args.video else os.path.join(project_root, detector.config['file_paths']['default_video_path'])
        output_dir = args.output if args.output else os.path.join(project_root, detector.config['file_paths']['default_output_dir'])
        
        # å¦‚æœæŒ‡å®šäº†å‘½ä»¤è¡Œå‚æ•°ï¼Œåˆ™è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®
        if args.threshold is not None:
            detector.operation_threshold = args.threshold
        
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(video_path):
            print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return
        
        print("ğŸš€ å¯åŠ¨è®¾å¤‡æ“ä½œæ£€æµ‹åˆ†æç³»ç»Ÿ V3 - æ™ºèƒ½é…ç½®")
        print(f"ğŸ“‹ é…ç½®æ–‡ä»¶: {args.config}")
        print(f"ğŸ“¹ è¾“å…¥è§†é¢‘: {video_path}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“ è·ç¦»é˜ˆå€¼: {detector.operation_threshold} åƒç´ ")
        
        # å¤„ç†è§†é¢‘
        # å¤„ç†è§†é¢‘
        detector.process_video(video_path, output_dir)
        
        print("âœ… åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
