#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®¾å¤‡æ“ä½œæ£€æµ‹ç³»ç»Ÿ
ç»“åˆç›®æ ‡æ£€æµ‹å’Œäººä½“å§¿æ€è¯†åˆ«ï¼Œåˆ†æäººå‘˜å¯¹7ç±»è®¾å¤‡çš„æ“ä½œè¡Œä¸º
"""

import os
import cv2
import numpy as np
import pandas as pd
from ultralytics import YOLO
import argparse
from collections import defaultdict
import json  # ä»…ç”¨äºä¿å­˜åˆ†ææŠ¥å‘Š
from datetime import datetime
import math
from PIL import Image, ImageDraw, ImageFont

# å¯¼å…¥é…ç½®ç®¡ç†å™¨
from config_manager import ConfigManager


class DevicePositionCache:
    """è®¾å¤‡ä½ç½®ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_age_seconds=15.0, min_confidence=0.5, smoothing_factor=0.8):
        """
        åˆå§‹åŒ–è®¾å¤‡ä½ç½®ç¼“å­˜
        
        Args:
            max_age_seconds: ç¼“å­˜æœ€å¤§å­˜æ´»æ—¶é—´(ç§’)
            min_confidence: æœ€ä½ç¼“å­˜ç½®ä¿¡åº¦é˜ˆå€¼
            smoothing_factor: ä½ç½®å¹³æ»‘ç³»æ•° (0-1, è¶Šå¤§è¶Šå¹³æ»‘)
        """
        self.cache = {}  # {class_id: CacheEntry}
        self.max_age_seconds = max_age_seconds
        self.min_confidence = min_confidence
        self.smoothing_factor = smoothing_factor
        
    class CacheEntry:
        """ç¼“å­˜æ¡ç›®"""
        def __init__(self, position, confidence, timestamp):
            self.position = position          # {'x': x, 'y': y}
            self.confidence = confidence      # æ£€æµ‹ç½®ä¿¡åº¦
            self.last_seen_time = timestamp   # æœ€åæ›´æ–°æ—¶é—´æˆ³(ç§’)
            self.hit_count = 1               # å‘½ä¸­æ¬¡æ•°
            self.total_confidence = confidence  # ç´¯ç§¯ç½®ä¿¡åº¦
    
    def update(self, class_id, position, confidence, timestamp):
        """
        æ›´æ–°è®¾å¤‡ä½ç½®ç¼“å­˜
        
        Args:
            class_id: è®¾å¤‡ç±»åˆ«ID
            position: ä½ç½®åæ ‡ {'x': x, 'y': y}
            confidence: æ£€æµ‹ç½®ä¿¡åº¦
            timestamp: å½“å‰æ—¶é—´æˆ³(ç§’)
        """
        # åªç¼“å­˜é«˜ç½®ä¿¡åº¦çš„æ£€æµ‹ç»“æœ
        if confidence < self.min_confidence:
            return
            
        if class_id in self.cache:
            # æ›´æ–°å·²å­˜åœ¨çš„ç¼“å­˜
            entry = self.cache[class_id]
            
            # ä½ç½®å¹³æ»‘å¤„ç†
            old_pos = entry.position
            new_x = old_pos['x'] * self.smoothing_factor + position['x'] * (1 - self.smoothing_factor)
            new_y = old_pos['y'] * self.smoothing_factor + position['y'] * (1 - self.smoothing_factor)
            
            entry.position = {'x': new_x, 'y': new_y}
            entry.confidence = max(entry.confidence, confidence)  # ä¿æŒæœ€é«˜ç½®ä¿¡åº¦
            entry.last_seen_time = timestamp
            entry.hit_count += 1
            entry.total_confidence += confidence
        else:
            # åˆ›å»ºæ–°çš„ç¼“å­˜æ¡ç›®
            self.cache[class_id] = self.CacheEntry(position.copy(), confidence, timestamp)
    
    def get_cached_position(self, class_id, current_timestamp):
        """
        è·å–ç¼“å­˜çš„è®¾å¤‡ä½ç½®
        
        Args:
            class_id: è®¾å¤‡ç±»åˆ«ID
            current_timestamp: å½“å‰æ—¶é—´æˆ³(ç§’)
            
        Returns:
            dict or None: ç¼“å­˜çš„ä½ç½®ä¿¡æ¯ï¼Œå¦‚æœè¿‡æœŸæˆ–ä¸å­˜åœ¨åˆ™è¿”å›None
        """
        if class_id not in self.cache:
            return None
            
        entry = self.cache[class_id]
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        age_seconds = current_timestamp - entry.last_seen_time
        if age_seconds > self.max_age_seconds:
            return None
            
        # è®¡ç®—ç¼“å­˜è´¨é‡å¾—åˆ† (ç»¼åˆç½®ä¿¡åº¦å’Œå‘½ä¸­æ¬¡æ•°)
        avg_confidence = entry.total_confidence / entry.hit_count
        quality_score = avg_confidence * min(1.0, entry.hit_count / 10.0)
        
        return {
            'position': entry.position.copy(),
            'confidence': entry.confidence,
            'quality_score': quality_score,
            'hit_count': entry.hit_count,
            'age_seconds': age_seconds
        }
    
    def cleanup_expired(self, current_timestamp):
        """
        æ¸…ç†è¿‡æœŸç¼“å­˜
        
        Args:
            current_timestamp: å½“å‰æ—¶é—´æˆ³(ç§’)
        """
        expired_ids = []
        for class_id, entry in self.cache.items():
            age_seconds = current_timestamp - entry.last_seen_time
            if age_seconds > self.max_age_seconds:
                expired_ids.append((class_id, age_seconds))
        
        for class_id, age in expired_ids:
            del self.cache[class_id]
        
        if expired_ids:
            print(f"ğŸ—‘ï¸  æ¸…ç†è¿‡æœŸç¼“å­˜: {[(id, f'{age:.1f}s') for id, age in expired_ids]}")
    
    def get_cache_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_entries': len(self.cache),
            'entries': {class_id: {
                'hit_count': entry.hit_count,
                'confidence': entry.confidence,
                'avg_confidence': entry.total_confidence / entry.hit_count
            } for class_id, entry in self.cache.items()}
        }


class OperationDetector:
    def __init__(self, project_root, config_file_path):
        """
        åˆå§‹åŒ–æ“ä½œæ£€æµ‹å™¨
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
            config_file_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.project_root = project_root
        
        # åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆä½¿ç”¨é…ç½®ç®¡ç†å™¨ï¼‰
        config_manager = ConfigManager()
        self.config = config_manager.load_config(config_file_path)
        
        # è®¾å¤‡ç±»åˆ«æ˜ å°„ï¼ˆä»é…ç½®ä¸­è·å–ï¼‰
        self.all_classes = self.config['all_classes']
        
        # ç›®æ ‡è®¾å¤‡ç±»åˆ«çš„æ˜ å°„
        # æ ¹æ®å®é™…æ£€æµ‹è¾“å‡ºç¡®å®šæ­£ç¡®çš„ç±»åˆ«æ˜ å°„
        class_name_to_id = {}
        
        try:
            classes_file = os.path.join(self.project_root, self.config['file_paths']['classes_file'])
            with open(classes_file, 'r', encoding='utf-8') as f:
                all_classes = [line.strip() for line in f.readlines()]
                for idx, class_name in enumerate(all_classes):
                    class_name_to_id[class_name] = idx
                    
            # æ ¹æ®å®é™…æ£€æµ‹åˆ°çš„ç±»åˆ«åç§°è¿›è¡Œæ˜ å°„
            self.device_classes = {}
            device_class_mappings = self.config['device_class_mappings']
            
            for class_name, device_type in device_class_mappings.items():
                if class_name in class_name_to_id:
                    self.device_classes[class_name_to_id[class_name]] = device_type
            
            print(f"âœ“ è®¾å¤‡ç±»åˆ«æ˜ å°„: {self.device_classes}")
            
        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–ç±»åˆ«æ–‡ä»¶å¤±è´¥ {e}, ä½¿ç”¨é»˜è®¤æ˜ å°„")
            # é»˜è®¤æ˜ å°„ä½œä¸ºåå¤‡ï¼ˆä»é…ç½®ä¸­è·å–ï¼‰
            self.device_classes = {int(k): v for k, v in self.config['default_device_classes'].items()}
        
        # æ“ä½œåˆ¤æ–­é˜ˆå€¼ï¼ˆåƒç´ è·ç¦»ï¼Œä»é…ç½®æ–‡ä»¶è·å–ï¼‰
        self.operation_threshold = self.config['thresholds']['operation_distance_threshold']
        
        # åŠ è½½æ¨¡å‹
        self.load_models()
        
        # æ“ä½œè®°å½•
        self.operation_records = defaultdict(list)
        
        # åˆå§‹åŒ–è®¾å¤‡ä½ç½®ç¼“å­˜ (ä»é…ç½®ä¸­è·å–å‚æ•°)
        cache_config = self.config.get('device_cache', {})
        self.device_cache = DevicePositionCache(
            max_age_seconds=cache_config.get('max_age_seconds', 15.0),
            min_confidence=cache_config.get('min_confidence_to_cache', 0.5),
            smoothing_factor=cache_config.get('cache_update_smoothing', 0.8)
        )
        
        # åŠ è½½å›ºå®šè®¾å¤‡åæ ‡
        self.fixed_device_coordinates = self.load_fixed_device_coordinates()
        
        # åŠ è½½ä¸­æ–‡å­—ä½“
        self.load_chinese_font()
    
    def load_fixed_device_coordinates(self):
        """åŠ è½½å›ºå®šè®¾å¤‡åæ ‡ä¿¡æ¯"""
        fixed_coords_file = os.path.join(self.project_root, self.config['file_paths']['fixed_coords_file'])
        fixed_coordinates = []
        
        try:
            with open(fixed_coords_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                
                i = 0
                while i < len(lines):
                    line = lines[i].strip()
                    
                    # æŸ¥æ‰¾ç›®æ ‡å¼€å§‹è¡Œ
                    if line.startswith('ç›®æ ‡'):
                        device_info = {}
                        i += 1
                        
                        # è§£æç±»åˆ«ä¿¡æ¯
                        if i < len(lines) and 'ç±»åˆ«:' in lines[i]:
                            class_line = lines[i].strip()
                            # æå–ç±»åˆ«åç§°å’ŒID
                            if '(' in class_line and 'ID:' in class_line:
                                class_name = class_line.split('ç±»åˆ«:')[1].split('(')[0].strip()
                                class_id_str = class_line.split('ID:')[1].split(')')[0].strip()
                                device_info['class_name'] = class_name
                                device_info['class_id'] = int(class_id_str)
                            i += 1
                        
                        # è§£æç½®ä¿¡åº¦
                        if i < len(lines) and 'ç½®ä¿¡åº¦:' in lines[i]:
                            conf_line = lines[i].strip()
                            confidence = float(conf_line.split('ç½®ä¿¡åº¦:')[1].strip())
                            device_info['confidence'] = confidence
                            i += 1
                        
                        # è·³è¿‡è¾¹æ¡†åæ ‡æ ‡é¢˜è¡Œ
                        if i < len(lines) and 'è¾¹æ¡†åæ ‡:' in lines[i]:
                            i += 1
                        
                        # è§£æåæ ‡ä¿¡æ¯
                        bbox_coords = {}
                        for _ in range(4):  # è¯»å–4ä¸ªè§’ç‚¹åæ ‡
                            if i < len(lines):
                                coord_line = lines[i].strip()
                                if '(' in coord_line and ')' in coord_line:
                                    # æå–åæ ‡
                                    coord_str = coord_line.split('(')[1].split(')')[0]
                                    x, y = map(float, coord_str.split(','))
                                    if 'å·¦ä¸Šè§’' in coord_line:
                                        bbox_coords['x1'] = x
                                        bbox_coords['y1'] = y
                                    elif 'å³ä¸‹è§’' in coord_line:
                                        bbox_coords['x2'] = x
                                        bbox_coords['y2'] = y
                                i += 1
                        
                        # è§£æä¸­å¿ƒç‚¹åæ ‡
                        if i < len(lines) and 'ä¸­å¿ƒç‚¹åæ ‡:' in lines[i]:
                            center_line = lines[i].strip()
                            if '(' in center_line and ')' in center_line:
                                coord_str = center_line.split('(')[1].split(')')[0]
                                center_x, center_y = map(float, coord_str.split(','))
                                device_info['center_x'] = center_x
                                device_info['center_y'] = center_y
                            i += 1
                        
                        # å¦‚æœè§£æåˆ°äº†æœ‰æ•ˆä¿¡æ¯ï¼Œæ·»åŠ åˆ°åˆ—è¡¨ä¸­
                        if 'class_id' in device_info and 'center_x' in device_info:
                            # è®¾ç½®è¾¹ç•Œæ¡†åæ ‡
                            if 'x1' in bbox_coords and 'x2' in bbox_coords:
                                device_info['bbox'] = [bbox_coords['x1'], bbox_coords['y1'], 
                                                     bbox_coords['x2'], bbox_coords['y2']]
                            else:
                                # å¦‚æœæ²¡æœ‰å®Œæ•´çš„è¾¹ç•Œæ¡†ä¿¡æ¯ï¼Œæ ¹æ®ä¸­å¿ƒç‚¹ä¼°ç®—
                                estimation_size = self.config['device_detection']['missing_device_estimation_size']
                                device_info['bbox'] = [device_info['center_x'] - estimation_size, device_info['center_y'] - estimation_size,
                                                     device_info['center_x'] + estimation_size, device_info['center_y'] + estimation_size]
                            
                            fixed_coordinates.append(device_info)
                    else:
                        i += 1
            
            print(f"âœ“ åŠ è½½å›ºå®šè®¾å¤‡åæ ‡: å…± {len(fixed_coordinates)} ä¸ªè®¾å¤‡")
            for device in fixed_coordinates:
                print(f"  - {device['class_name']} (ID: {device['class_id']}): ä¸­å¿ƒç‚¹ ({device['center_x']:.1f}, {device['center_y']:.1f})")
            
        except Exception as e:
            print(f"è­¦å‘Š: åŠ è½½å›ºå®šè®¾å¤‡åæ ‡å¤±è´¥ {e}")
            
        return fixed_coordinates
        
    def load_chinese_font(self):
        """åŠ è½½ä¸­æ–‡å­—ä½“"""
        try:
            # ä¸­æ–‡å­—ä½“è·¯å¾„
            font_path = os.path.join(self.project_root, self.config['font_settings']['chinese_font_path'])
            if os.path.exists(font_path):
                font_size_normal = self.config['font_settings']['font_size_normal']
                font_size_small = self.config['font_settings']['font_size_small']
                self.chinese_font = ImageFont.truetype(font_path, font_size_normal)
                self.chinese_font_small = ImageFont.truetype(font_path, font_size_small)
                print(f"âœ“ ä¸­æ–‡å­—ä½“åŠ è½½æˆåŠŸ: {font_path}")
            else:
                print(f"è­¦å‘Š: ä¸­æ–‡å­—ä½“æ–‡ä»¶ä¸å­˜åœ¨: {font_path}")
                self.chinese_font = ImageFont.load_default()
                self.chinese_font_small = ImageFont.load_default()
        except Exception as e:
            print(f"è­¦å‘Š: ä¸­æ–‡å­—ä½“åŠ è½½å¤±è´¥ {e}, ä½¿ç”¨é»˜è®¤å­—ä½“")
            self.chinese_font = ImageFont.load_default()
            self.chinese_font_small = ImageFont.load_default()
    
    def draw_chinese_text(self, image, text, position, font, color=(255, 255, 255)):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬
        Args:
            image: OpenCVå›¾åƒ (BGRæ ¼å¼)
            text: è¦ç»˜åˆ¶çš„æ–‡æœ¬
            position: æ–‡æœ¬ä½ç½® (x, y)
            font: PILå­—ä½“å¯¹è±¡
            color: æ–‡æœ¬é¢œè‰² (B, G, R)
        Returns:
            ç»˜åˆ¶äº†æ–‡æœ¬çš„å›¾åƒ
        """
        # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPILå›¾åƒ
        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)
        
        # ç»˜åˆ¶æ–‡æœ¬ (PILä½¿ç”¨RGBæ ¼å¼)
        rgb_color = (color[2], color[1], color[0])  # BGRè½¬RGB
        draw.text(position, text, font=font, fill=rgb_color)
        
        # è½¬æ¢å›OpenCVæ ¼å¼
        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
    def load_models(self):
        """åŠ è½½ç›®æ ‡æ£€æµ‹å’Œå§¿æ€è¯†åˆ«æ¨¡å‹"""
        try:
            # åŠ è½½ç›®æ ‡æ£€æµ‹æ¨¡å‹
            detection_model_path = os.path.join(
                self.project_root, self.config['models']['detection_model_path']
            )
            self.detection_model = YOLO(detection_model_path)
            print(f"âœ“ ç›®æ ‡æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ: {detection_model_path}")
            
            # åŠ è½½å§¿æ€è¯†åˆ«æ¨¡å‹
            pose_model_path = os.path.join(self.project_root, self.config['models']['pose_model_path'])
            self.pose_model = YOLO(pose_model_path)
            print(f"âœ“ å§¿æ€è¯†åˆ«æ¨¡å‹åŠ è½½æˆåŠŸ: {pose_model_path}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def get_hand_keypoints(self, keypoints):
        """
        ä»YOLO poseæ£€æµ‹ç»“æœä¸­æå–æ‰‹éƒ¨å…³é”®ç‚¹
        è¿”å›å·¦å³æ‰‹è…•å’Œæ‰‹è‚˜çš„åæ ‡
        """
        # YOLO poseå…³é”®ç‚¹ç´¢å¼•ï¼ˆCOCOæ ¼å¼ï¼‰- ä»é…ç½®ä¸­è·å–
        keypoint_indices = self.config['keypoint_indices']
        
        hand_points = {}
        
        for point_name, index in keypoint_indices.items():
            if index < len(keypoints):
                x, y, confidence = keypoints[index]
                # ä½¿ç”¨é…ç½®ä¸­çš„ç½®ä¿¡åº¦é˜ˆå€¼
                keypoint_threshold = self.config['thresholds']['keypoint_confidence_threshold']
                if confidence > keypoint_threshold:
                    hand_points[point_name] = {'x': float(x), 'y': float(y), 'confidence': float(confidence)}
                else:
                    hand_points[point_name] = {'x': None, 'y': None, 'confidence': float(confidence)}
            else:
                hand_points[point_name] = {'x': None, 'y': None, 'confidence': 0.0}
        
        return hand_points
    
    def calculate_weighted_hand_center(self, hand_points):
        """
        ä½¿ç”¨åŠ æƒå…¬å¼è®¡ç®—æ‰‹éƒ¨ä¸­å¿ƒç‚¹
        å…¬å¼: ä¸­å¿ƒç‚¹ä½ç½® = 0.35*left_wrist + 0.35*right_wrist + 0.15*right_elbow + 0.15*left_elbow
        """
        left_wrist = hand_points['left_wrist']
        right_wrist = hand_points['right_wrist']
        left_elbow = hand_points['left_elbow']
        right_elbow = hand_points['right_elbow']
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æœ‰æ•ˆç‚¹æ¥è®¡ç®—ä¸­å¿ƒç‚¹
        valid_points = []
        weights = []
        
        # ä»é…ç½®æ–‡ä»¶è·å–æƒé‡
        weights_config = self.config['hand_center_weights']
        
        if left_wrist['x'] is not None and left_wrist['y'] is not None:
            valid_points.append((left_wrist['x'], left_wrist['y']))
            weights.append(weights_config['left_wrist_weight'])
            
        if right_wrist['x'] is not None and right_wrist['y'] is not None:
            valid_points.append((right_wrist['x'], right_wrist['y']))
            weights.append(weights_config['right_wrist_weight'])
            
        if left_elbow['x'] is not None and left_elbow['y'] is not None:
            valid_points.append((left_elbow['x'], left_elbow['y']))
            weights.append(weights_config['left_elbow_weight'])
            
        if right_elbow['x'] is not None and right_elbow['y'] is not None:
            valid_points.append((right_elbow['x'], right_elbow['y']))
            weights.append(weights_config['right_elbow_weight'])
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç‚¹ï¼Œè¿”å›None
        if len(valid_points) == 0:
            return {'x': None, 'y': None}
        
        # æ ¹æ®æœ‰æ•ˆç‚¹é‡æ–°è®¡ç®—æƒé‡ï¼ˆç¡®ä¿æƒé‡å’Œä¸º1ï¼‰
        total_weight = sum(weights)
        normalized_weights = [w / total_weight for w in weights]
        
        # è®¡ç®—åŠ æƒä¸­å¿ƒç‚¹
        center_x = sum(p[0] * w for p, w in zip(valid_points, normalized_weights))
        center_y = sum(p[1] * w for p, w in zip(valid_points, normalized_weights))
        
        return {'x': float(center_x), 'y': float(center_y)}
    
    
    
    def calculate_center_point(self, points):
        """è®¡ç®—å¤šä¸ªç‚¹çš„ä¸­å¿ƒä½ç½®ï¼Œæ”¯æŒåˆ—è¡¨æˆ–å­—å…¸è¾“å…¥"""
        # å¦‚æœæ˜¯å­—å…¸ï¼ˆå¦‚ hand_pointsï¼‰ï¼Œå–å…¶ values
        if isinstance(points, dict):
            points = list(points.values())
        valid_points = []
        for point in points:
            if isinstance(point, dict) and point.get('x') is not None and point.get('y') is not None:
                valid_points.append((point['x'], point['y']))
        if len(valid_points) == 0:
            return {'x': None, 'y': None}
        center_x = sum(p[0] for p in valid_points) / len(valid_points)
        center_y = sum(p[1] for p in valid_points) / len(valid_points)
        return {'x': float(center_x), 'y': float(center_y)}
    
    
    
    
    def calculate_distance(self, point1, point2):
        """è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»"""
        if (point1['x'] is None or point1['y'] is None or 
            point2['x'] is None or point2['y'] is None):
            return float('inf')
        
        dx = point1['x'] - point2['x']
        dy = point1['y'] - point2['y']
        return math.sqrt(dx * dx + dy * dy)
    
    def detect_objects(self, frame, frame_number=0, timestamp=0.0):
        """
        ä½¿ç”¨ç›®æ ‡æ£€æµ‹æ¨¡å‹æ£€æµ‹è®¾å¤‡ï¼Œé‡‡ç”¨ä¸‰çº§å›é€€ç­–ç•¥
        
        Args:
            frame: è¾“å…¥å›¾åƒå¸§
            frame_number: å½“å‰å¸§å·
            timestamp: å½“å‰æ—¶é—´æˆ³(ç§’)ï¼ˆç”¨äºç¼“å­˜ç®¡ç†ï¼‰
            
        Returns:
            list: æ£€æµ‹åˆ°çš„è®¾å¤‡åˆ—è¡¨
        """
        results = self.detection_model(frame)
        detected_objects = []
        detected_device_ids = set()  # è®°å½•å·²æ£€æµ‹åˆ°çš„è®¾å¤‡ID
        
        # è®¾å¤‡ç±»åˆ«æ˜ å°„ï¼ˆä»é…ç½®ä¸­è·å–ï¼‰
        device_mapping = self.config['device_mapping']
        detection_threshold = self.config['thresholds']['detection_confidence_threshold']
        
        # æ¸…ç†è¿‡æœŸç¼“å­˜
        self.device_cache.cleanup_expired(timestamp)
        
        # ç¬¬ä¸€çº§ï¼šä»YOLOæ¨¡å‹å®æ—¶æ£€æµ‹ç»“æœä¸­æå–è®¾å¤‡
        for r in results:
            if r.boxes is not None:
                for box in r.boxes:
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    # è®¡ç®—ä¸­å¿ƒç‚¹
                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    
                    # è·å–ç±»åˆ«å’Œç½®ä¿¡åº¦
                    class_id = int(box.cls[0].cpu().numpy())
                    confidence = float(box.conf[0].cpu().numpy())
                    
                    if confidence > detection_threshold:  # ç½®ä¿¡åº¦é˜ˆå€¼
                        # è¿‡æ»¤æ‰"äºº"ç±»åˆ«ï¼Œå› ä¸ºæˆ‘ä»¬ç”¨å§¿æ€è¯†åˆ«æ¥æ£€æµ‹äººå‘˜
                        if class_id == self.config['device_detection']['person_class_id']:  # ID 3 æ˜¯"äºº"ç±»åˆ«
                            continue
                            
                        class_name = self.device_classes.get(class_id, f"Unknown_{class_id}")
                        if class_name.startswith("Unknown_"):
                            # å°è¯•ä½¿ç”¨æ¨¡å‹çš„nameså±æ€§è·å–åŸå§‹ç±»åˆ«åç§°
                            try:
                                if hasattr(results[0], 'names') and class_id in results[0].names:
                                    original_name = results[0].names[class_id]
                                    # æ£€æŸ¥åŸå§‹åç§°æ˜¯å¦æ˜¯æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡ç±»åˆ«
                                    if original_name in device_mapping:
                                        class_name = device_mapping[original_name]
                                    else:
                                        # å¦‚æœä¸æ˜¯æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡ï¼Œè·³è¿‡
                                        continue
                                elif class_id < len(self.all_classes):
                                    original_name = self.all_classes[class_id]
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡
                                    if original_name in device_mapping:
                                        class_name = device_mapping[original_name]
                                    else:
                                        # å¦‚æœä¸æ˜¯æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡ï¼Œè·³è¿‡
                                        continue
                                else:
                                    # å¦‚æœæ— æ³•è·å–ç±»åˆ«åç§°ï¼Œè·³è¿‡
                                    continue
                            except:
                                # å¦‚æœå‡ºç°å¼‚å¸¸ï¼Œè·³è¿‡
                                continue
                        
                        detected_objects.append({
                            'class_id': class_id,
                            'class_name': class_name,
                            'center': {'x': center_x, 'y': center_y},
                            'bbox': [x1, y1, x2, y2],
                            'confidence': confidence,
                            'source': 'detection'  # æ ‡è®°æ¥æºä¸ºæ£€æµ‹
                        })
                        detected_device_ids.add(class_id)
                        
                        # æ›´æ–°è®¾å¤‡ä½ç½®ç¼“å­˜
                        self.device_cache.update(class_id, {'x': center_x, 'y': center_y}, confidence, timestamp)
        
        # è·å–æˆ‘ä»¬å…³å¿ƒçš„æ‰€æœ‰è®¾å¤‡ç±»åˆ«ID
        target_device_ids = set(self.device_classes.keys())
        missing_device_ids = target_device_ids - detected_device_ids
        
        if missing_device_ids:
            print(f"ğŸ“ æœªæ£€æµ‹åˆ°è®¾å¤‡ {missing_device_ids}ï¼Œå¯åŠ¨å›é€€ç­–ç•¥")
            
            cache_recovered_ids = set()
            
            # ç¬¬äºŒçº§ï¼šå¯¹äºæœªæ£€æµ‹åˆ°çš„è®¾å¤‡ï¼Œå°è¯•ä½¿ç”¨åŠ¨æ€ç¼“å­˜
            for device_id in missing_device_ids:
                cached_info = self.device_cache.get_cached_position(device_id, timestamp)
                if cached_info:
                    class_name = self.device_classes.get(device_id, f"Unknown_{device_id}")
                    position = cached_info['position']
                    
                    # ä¼°ç®—è¾¹ç•Œæ¡† (ä½¿ç”¨ç¼“å­˜ä½ç½®å‘¨å›´çš„é»˜è®¤å¤§å°)
                    estimation_size = self.config['device_detection']['missing_device_estimation_size']
                    half_size = estimation_size // 2
                    bbox = [
                        position['x'] - half_size, position['y'] - half_size,
                        position['x'] + half_size, position['y'] + half_size
                    ]
                    
                    detected_objects.append({
                        'class_id': device_id,
                        'class_name': class_name,
                        'center': position,
                        'bbox': bbox,
                        'confidence': cached_info['confidence'] * 0.8,  # ç¼“å­˜ç½®ä¿¡åº¦æ‰“æŠ˜
                        'source': 'dynamic_cache',  # æ ‡è®°æ¥æºä¸ºåŠ¨æ€ç¼“å­˜
                        'cache_quality': cached_info['quality_score'],
                        'cache_age': cached_info['age_seconds']
                    })
                    cache_recovered_ids.add(device_id)
                    print(f"  ğŸ”„ ç¼“å­˜æ¢å¤: {class_name} ä½ç½®({position['x']:.1f}, {position['y']:.1f}) "
                          f"è´¨é‡={cached_info['quality_score']:.2f} å¹´é¾„={cached_info['age_seconds']:.1f}s")
            
            # ç¬¬ä¸‰çº§ï¼šå¯¹äºä»æœªæ¢å¤çš„è®¾å¤‡ï¼Œä½¿ç”¨é™æ€å›ºå®šåæ ‡
            still_missing_ids = missing_device_ids - cache_recovered_ids
            
            if still_missing_ids and self.fixed_device_coordinates:
                print(f"  ğŸ“Œ ä½¿ç”¨å›ºå®šåæ ‡è¡¥å……è®¾å¤‡: {still_missing_ids}")
                
                for fixed_device in self.fixed_device_coordinates:
                    device_id = fixed_device['class_id']
                    
                    # å¦‚æœè¿™ä¸ªè®¾å¤‡ä»ç„¶ç¼ºå¤±ä¸”æ˜¯æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡
                    if device_id in still_missing_ids:
                        class_name = self.device_classes.get(device_id, f"Unknown_{device_id}")
                        
                        # ä½¿ç”¨å›ºå®šåæ ‡åˆ›å»ºè®¾å¤‡å¯¹è±¡
                        fixed_confidence = self.config['thresholds']['fixed_coordinate_confidence']
                        detected_objects.append({
                            'class_id': device_id,
                            'class_name': class_name,
                            'center': {'x': fixed_device['center_x'], 'y': fixed_device['center_y']},
                            'bbox': fixed_device['bbox'],
                            'confidence': fixed_confidence,  # ä»é…ç½®ä¸­è·å–å›ºå®šåæ ‡ç½®ä¿¡åº¦
                            'source': 'fixed_coordinates'  # æ ‡è®°æ¥æºä¸ºå›ºå®šåæ ‡
                        })
                        print(f"    âš¡ æ·»åŠ å›ºå®šåæ ‡: {class_name} ä¸­å¿ƒç‚¹({fixed_device['center_x']:.1f}, {fixed_device['center_y']:.1f})")
        
        return detected_objects
    
    def detect_poses(self, frame):
        """ä½¿ç”¨å§¿æ€è¯†åˆ«æ¨¡å‹æ£€æµ‹äººä½“å§¿æ€"""
        results = self.pose_model(frame)
        detected_persons = []
        
        for r in results:
            if r.keypoints is not None:
                for i, keypoints in enumerate(r.keypoints.data):
                    # æå–æ‰‹éƒ¨å…³é”®ç‚¹
                    hand_points = self.get_hand_keypoints(keypoints)
                    
                    # ä½¿ç”¨åŠ æƒå…¬å¼è®¡ç®—æ‰‹éƒ¨ä¸­å¿ƒç‚¹
                    # å…¬å¼å‚æ•°ä»é…ç½®æ–‡ä»¶è·å–  2é’Ÿé€‰æ‹©ï¼Œä½¿ç”¨åŠ æƒæˆ–è€…ç›´æ¥å¹³å‡
                    hand_center = self.calculate_weighted_hand_center(hand_points)
                    
                    if hand_center['x'] is not None:  # åªæœ‰å½“èƒ½è®¡ç®—å‡ºæ‰‹éƒ¨ä¸­å¿ƒæ—¶æ‰æ·»åŠ 
                        detected_persons.append({
                            'person_id': i,
                            'hand_keypoints': hand_points,
                            'hand_center': hand_center
                        })
        
        return detected_persons
    
    def analyze_operations(self, persons, objects, frame_number, timestamp):
        """åˆ†æäººå‘˜æ“ä½œè¡Œä¸º"""
        operations = []
        
        for person in persons:
            if person['hand_center']['x'] is None:
                continue
                
            min_distance = float('inf')
            closest_object = None
            
            # æ‰¾åˆ°ç¦»æ‰‹éƒ¨ä¸­å¿ƒæœ€è¿‘çš„ç‰©ä½“
            for obj in objects:
                distance = self.calculate_distance(person['hand_center'], obj['center'])
                if distance < min_distance:
                    min_distance = distance
                    closest_object = obj
            
            # å¦‚æœè·ç¦»å°äºé˜ˆå€¼ï¼Œè®¤ä¸ºæ­£åœ¨æ“ä½œ
            if closest_object and min_distance <= self.operation_threshold:
                operation = {
                    'frame_number': frame_number,
                    'timestamp': timestamp,
                    'person_id': person['person_id'],
                    'device_class_id': closest_object['class_id'],
                    'device_name': closest_object['class_name'],
                    'distance': min_distance,
                    'hand_center': person['hand_center'],
                    'device_center': closest_object['center'],
                    'device_confidence': closest_object['confidence']
                }
                operations.append(operation)
                
                # è®°å½•æ“ä½œå†å²
                self.operation_records[closest_object['class_id']].append(operation)
        
        return operations
    
    def draw_annotations(self, frame, objects, persons, operations):
        """åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœå’Œæ“ä½œåˆ†æ"""
        annotated_frame = frame.copy()
        
        # ç»˜åˆ¶æ£€æµ‹åˆ°çš„ç‰©ä½“
        for obj in objects:
            center_x, center_y = int(obj['center']['x']), int(obj['center']['y'])
            
            # è®¾å¤‡ä¸­å¿ƒç‚¹é¢œè‰²å’ŒåŠå¾„ä»é…ç½®è·å–
            center_color = tuple(self.config['visualization']['device_center_color'])
            center_radius = self.config['visualization']['device_center_radius']
            
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(annotated_frame, (center_x, center_y), center_radius, center_color, -1)
        
        # ç»˜åˆ¶äººä½“æ‰‹éƒ¨å…³é”®ç‚¹
        hand_colors = self.config['hand_colors']
        keypoint_radius = self.config['visualization']['keypoint_radius']
        
        for person in persons:
            # ç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹
            for point_name, point_data in person['hand_keypoints'].items():
                if point_data['x'] is not None and point_data['y'] is not None:
                    x, y = int(point_data['x']), int(point_data['y'])
                    color = tuple(hand_colors.get(point_name, [255, 255, 255]))
                    cv2.circle(annotated_frame, (x, y), keypoint_radius, color, -1)
                    cv2.putText(annotated_frame, point_name[:5], (x+8, y-8), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
            
            # ç»˜åˆ¶æ‰‹éƒ¨ä¸­å¿ƒç‚¹
            if person['hand_center']['x'] is not None:
                center_x = int(person['hand_center']['x'])
                center_y = int(person['hand_center']['y'])
                hand_center_color = tuple(self.config['visualization']['hand_center_color'])
                hand_center_radius = self.config['visualization']['hand_center_radius']
                cv2.circle(annotated_frame, (center_x, center_y), hand_center_radius, hand_center_color, -1)  # çº¢è‰²
                cv2.putText(annotated_frame, f'P{person["person_id"]}', (center_x+12, center_y-12), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        # ç»˜åˆ¶æ“ä½œè¿çº¿å’Œæ ‡æ³¨
        for op in operations:
            hand_x = int(op['hand_center']['x'])
            hand_y = int(op['hand_center']['y'])
            device_x = int(op['device_center']['x'])
            device_y = int(op['device_center']['y'])
            
            # ç»˜åˆ¶è¿çº¿
            line_color = tuple(self.config['visualization']['operation_line_color'])
            line_thickness = self.config['visualization']['operation_line_thickness']
            cv2.line(annotated_frame, (hand_x, hand_y), (device_x, device_y), line_color, line_thickness)
            
            # æ ‡æ³¨æ“ä½œä¿¡æ¯ï¼ˆä½¿ç”¨ä¸­æ–‡å­—ä½“ï¼‰
            mid_x = (hand_x + device_x) // 2
            mid_y = (hand_y + device_y) // 2
            operation_text = f"æ“ä½œä¸­: {op['device_name']}"
            distance_text = f"è·ç¦»: {op['distance']:.1f}px"
            
            # ä½¿ç”¨ä¸­æ–‡å­—ä½“ç»˜åˆ¶æ“ä½œä¿¡æ¯
            text_color = tuple(self.config['visualization']['operation_text_color'])
            annotated_frame = self.draw_chinese_text(
                annotated_frame, operation_text, (mid_x, mid_y-25), self.chinese_font_small, text_color
            )
            annotated_frame = self.draw_chinese_text(
                annotated_frame, distance_text, (mid_x, mid_y+5), self.chinese_font_small, text_color
            )
        
        return annotated_frame
    
    def process_video(self, video_path, output_dir):
        """å¤„ç†è§†é¢‘æ–‡ä»¶"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # éªŒè¯å¸§ç‡æœ‰æ•ˆæ€§ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä½œä¸ºå›é€€
        if fps <= 0 or fps > 240:
            original_fps = fps
            fps = self.config['video_processing']['fps_assumption']
            print(f"âš ï¸  è§†é¢‘å¸§ç‡æ— æ•ˆ ({original_fps} FPS)ï¼Œä½¿ç”¨é…ç½®ä¸­çš„å›é€€å¸§ç‡: {fps} FPS")
        
        # ä¿å­˜å®é™…ä½¿ç”¨çš„å¸§ç‡ä¾›åç»­è®¡ç®—ä½¿ç”¨
        self.actual_fps = fps
        
        print(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps} FPS, å…± {total_frames} å¸§")
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        output_video_path = os.path.join(output_dir, 'operation_analysis.mp4')
        out_video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
        
        # æ•°æ®è®°å½•
        all_frame_data = []
        frame_count = 0
        
        print("å¼€å§‹å¤„ç†è§†é¢‘...")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            timestamp = frame_count / fps
            
            if frame_count % 30 == 0:  # æ¯30å¸§æ˜¾ç¤ºè¿›åº¦
                print(f"å¤„ç†è¿›åº¦: {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%)")
            
            # æ£€æµ‹ç‰©ä½“å’Œäººä½“å§¿æ€
            detected_objects = self.detect_objects(frame, frame_count, timestamp)
            detected_persons = self.detect_poses(frame)
            
            # åˆ†ææ“ä½œè¡Œä¸º
            operations = self.analyze_operations(detected_persons, detected_objects, frame_count, timestamp)
            
            # ç»˜åˆ¶æ ‡æ³¨
            annotated_frame = self.draw_annotations(frame, detected_objects, detected_persons, operations)
            
            # å†™å…¥è§†é¢‘
            out_video.write(annotated_frame)
            
            # è®°å½•å¸§æ•°æ®
            frame_data = {
                'frame_number': frame_count,
                'timestamp': timestamp,
                'detected_objects': detected_objects,
                'detected_persons': detected_persons,
                'operations': operations
            }
            all_frame_data.append(frame_data)
        
        cap.release()
        out_video.release()
        
        print(f"è§†é¢‘å¤„ç†å®Œæˆï¼å…±å¤„ç† {frame_count} å¸§")
        print(f"æ ‡æ³¨è§†é¢‘ä¿å­˜ä¸º: {output_video_path}")
        
        # ä¿å­˜åˆ†æç»“æœ
        self.save_analysis_results(all_frame_data, output_dir)
        
        return all_frame_data
    
    def save_analysis_results(self, frame_data, output_dir):
        """ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶"""
        
        # 1. è®¡ç®—æ¯ä¸ªè®¾å¤‡çš„æ“ä½œæ—¶é—´ç»Ÿè®¡
        device_operation_stats = self.calculate_operation_time_stats()
        
        stats_df = pd.DataFrame([
            {
                'device_class_id': device_id,
                'device_name': self.device_classes.get(device_id, f"Unknown_{device_id}"),
                'total_operation_frames': stats['total_frames'],
                'total_operation_time_seconds': stats['total_time'],
                'operation_episodes': stats['episodes'],
                'average_distance': stats['avg_distance']
            }
            for device_id, stats in device_operation_stats.items()
        ])
        
        stats_csv_path = os.path.join(output_dir, 'device_operation_stats.csv')
        stats_df.to_csv(stats_csv_path, index=False, encoding='utf-8')
        print(f"è®¾å¤‡æ“ä½œç»Ÿè®¡ä¿å­˜ä¸º: {stats_csv_path}")
        
        # 2. ä¿å­˜å®Œæ•´çš„åˆ†ææŠ¥å‘Š
        report = {
            'analysis_info': {
                'total_frames': len(frame_data),
                'total_duration_seconds': frame_data[-1]['timestamp'] if frame_data else 0,
                'operation_threshold_pixels': self.operation_threshold,
                'device_classes': self.device_classes,
                'analysis_timestamp': datetime.now().isoformat()
            },
            'device_operation_summary': device_operation_stats
        }
        
        report_path = os.path.join(output_dir, 'analysis_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"åˆ†ææŠ¥å‘Šä¿å­˜ä¸º: {report_path}")
        
        # 4. æ‰“å°æ‘˜è¦ä¿¡æ¯
        print("\n" + "="*50)
        print("æ“ä½œåˆ†ææ‘˜è¦")
        print("="*50)
        
        if device_operation_stats:
            print("\nå„è®¾å¤‡æ“ä½œæ—¶é—´ç»Ÿè®¡:")
            for device_id, stats in device_operation_stats.items():
                device_name = self.device_classes.get(device_id, f"Unknown_{device_id}")
                print(f"  {device_name}:")
                print(f"    - æ“ä½œæ—¶é—´: {stats['total_time']:.2f} ç§’")
                print(f"    - æ“ä½œå¸§æ•°: {stats['total_frames']} å¸§")
                print(f"    - æ“ä½œæ¬¡æ•°: {stats['episodes']} æ¬¡")
                print(f"    - å¹³å‡è·ç¦»: {stats['avg_distance']:.2f} åƒç´ ")
        else:
            print("æœªæ£€æµ‹åˆ°ä»»ä½•æ“ä½œè¡Œä¸º")
    
    def calculate_operation_time_stats(self):
        """è®¡ç®—æ¯ä¸ªè®¾å¤‡çš„æ“ä½œæ—¶é—´ç»Ÿè®¡"""
        stats = {}
        
        for device_id, operations in self.operation_records.items():
            if not operations:
                continue
            
            # æŒ‰æ—¶é—´æ’åº
            operations_sorted = sorted(operations, key=lambda x: x['timestamp'])
            
            # è®¡ç®—è¿ç»­æ“ä½œçš„æ—¶é—´æ®µ
            episodes = []
            current_episode = [operations_sorted[0]]
            
            for i in range(1, len(operations_sorted)):
                # å¦‚æœä¸¤ä¸ªæ“ä½œä¹‹é—´çš„æ—¶é—´é—´éš”å°äº2ç§’ï¼Œè®¤ä¸ºæ˜¯è¿ç»­æ“ä½œ
                if operations_sorted[i]['timestamp'] - operations_sorted[i-1]['timestamp'] <= 2.0:
                    current_episode.append(operations_sorted[i])
                else:
                    episodes.append(current_episode)
                    current_episode = [operations_sorted[i]]
            
            episodes.append(current_episode)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            total_frames = len(operations)
            total_time = sum(len(episode) / self.actual_fps for episode in episodes)  # ä½¿ç”¨å®é™…å¸§ç‡
            avg_distance = sum(op['distance'] for op in operations) / len(operations)
            
            stats[device_id] = {
                'total_frames': total_frames,
                'total_time': total_time,
                'episodes': len(episodes),
                'avg_distance': avg_distance
            }
        
        return stats


def main():
    """ä¸»å‡½æ•°"""
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    
    # é»˜è®¤YAMLé…ç½®æ–‡ä»¶è·¯å¾„
    default_config_path = os.path.join(project_root, 'config.yaml')
    
    parser = argparse.ArgumentParser(description='è®¾å¤‡æ“ä½œæ£€æµ‹åˆ†æç³»ç»Ÿ V3')
    parser.add_argument('--config', type=str, default=default_config_path,
                       help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)')
    parser.add_argument('--video', type=str, default=None,
                       help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„ (å¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®)')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºç»“æœç›®å½•è·¯å¾„ (å¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®)')
    parser.add_argument('--threshold', type=float, default=None,
                       help='æ“ä½œåˆ¤æ–­è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰ (å¯é€‰ï¼Œä¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.config):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        return
    
    try:
        # åˆå§‹åŒ–æ£€æµ‹å™¨ï¼Œä¼ å…¥é…ç½®æ–‡ä»¶è·¯å¾„
        detector = OperationDetector(project_root, args.config)
        
        # ä»é…ç½®æ–‡ä»¶è·å–é»˜è®¤å‚æ•°ï¼Œæˆ–ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
        video_path = args.video if args.video else os.path.join(project_root, detector.config['file_paths']['default_video_path'])
        output_dir = args.output if args.output else os.path.join(project_root, detector.config['file_paths']['default_output_dir'])
        
        # å¦‚æœæŒ‡å®šäº†å‘½ä»¤è¡Œå‚æ•°ï¼Œåˆ™è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®
        if args.threshold is not None:
            detector.operation_threshold = args.threshold
        
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(video_path):
            print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return
        
        print("ğŸš€ å¯åŠ¨è®¾å¤‡æ“ä½œæ£€æµ‹åˆ†æç³»ç»Ÿ V3 - æ™ºèƒ½é…ç½®")
        print(f"ğŸ“‹ é…ç½®æ–‡ä»¶: {args.config}")
        print(f"ğŸ“¹ è¾“å…¥è§†é¢‘: {video_path}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“ è·ç¦»é˜ˆå€¼: {detector.operation_threshold} åƒç´ ")
        
        # å¤„ç†è§†é¢‘
        # å¤„ç†è§†é¢‘
        _ = detector.process_video(video_path, output_dir)
        
        print("âœ… åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
