#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®¾å¤‡æ“ä½œæ£€æµ‹ç³»ç»Ÿ
ç»“åˆç›®æ ‡æ£€æµ‹å’Œäººä½“å§¿æ€è¯†åˆ«ï¼Œåˆ†æäººå‘˜å¯¹7ç±»è®¾å¤‡çš„æ“ä½œè¡Œä¸º
"""

import os
import cv2
import numpy as np
import pandas as pd
from ultralytics import YOLO
import argparse
from collections import defaultdict
import json
from datetime import datetime
import math
from PIL import Image, ImageDraw, ImageFont


class OperationDetector:
    def __init__(self, project_root, classes_file, operation_threshold, config):
        """
        åˆå§‹åŒ–æ“ä½œæ£€æµ‹å™¨
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
            classes_file: è®¾å¤‡ç±»åˆ«æ–‡ä»¶è·¯å¾„
            operation_threshold: æ“ä½œåˆ¤æ–­è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰å›ºå®šå€¼
        """
        self.project_root = project_root
        self.config = config
        
        # è®¾å¤‡ç±»åˆ«æ˜ å°„ï¼ˆä»é…ç½®ä¸­è·å–ï¼‰
        self.all_classes = config['all_classes']
        
        # ç›®æ ‡è®¾å¤‡ç±»åˆ«çš„æ˜ å°„
        # æ ¹æ®å®é™…æ£€æµ‹è¾“å‡ºç¡®å®šæ­£ç¡®çš„ç±»åˆ«æ˜ å°„
        class_name_to_id = {}
        
        try:
            with open(classes_file, 'r', encoding='utf-8') as f:
                all_classes = [line.strip() for line in f.readlines()]
                for idx, class_name in enumerate(all_classes):
                    class_name_to_id[class_name] = idx
                    
            # æ ¹æ®å®é™…æ£€æµ‹åˆ°çš„ç±»åˆ«åç§°è¿›è¡Œæ˜ å°„
            self.device_classes = {}
            device_class_mappings = config['device_class_mappings']
            
            for class_name, device_type in device_class_mappings.items():
                if class_name in class_name_to_id:
                    self.device_classes[class_name_to_id[class_name]] = device_type
            
            print(f"âœ“ è®¾å¤‡ç±»åˆ«æ˜ å°„: {self.device_classes}")
            
        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–ç±»åˆ«æ–‡ä»¶å¤±è´¥ {e}, ä½¿ç”¨é»˜è®¤æ˜ å°„")
            # é»˜è®¤æ˜ å°„ä½œä¸ºåå¤‡ï¼ˆä»é…ç½®ä¸­è·å–ï¼‰
            self.device_classes = config['default_device_classes']
        
        # æ“ä½œåˆ¤æ–­é˜ˆå€¼ï¼ˆåƒç´ è·ç¦»ï¼Œä»å‚æ•°ä¼ å…¥ï¼‰
        self.operation_threshold = operation_threshold
        
        # åŠ è½½æ¨¡å‹
        self.load_models()
        
        # æ“ä½œè®°å½•
        self.operation_records = defaultdict(list)
        
        # åŠ è½½å›ºå®šè®¾å¤‡åæ ‡
        self.fixed_device_coordinates = self.load_fixed_device_coordinates()
        
        # åŠ è½½ä¸­æ–‡å­—ä½“
        self.load_chinese_font()
        
    def load_fixed_device_coordinates(self):
        """åŠ è½½å›ºå®šè®¾å¤‡åæ ‡ä¿¡æ¯"""
        fixed_coords_file = os.path.join(self.project_root, self.config['fixed_coords_file'])
        fixed_coordinates = []
        
        try:
            with open(fixed_coords_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                
                i = 0
                while i < len(lines):
                    line = lines[i].strip()
                    
                    # æŸ¥æ‰¾ç›®æ ‡å¼€å§‹è¡Œ
                    if line.startswith('ç›®æ ‡'):
                        device_info = {}
                        i += 1
                        
                        # è§£æç±»åˆ«ä¿¡æ¯
                        if i < len(lines) and 'ç±»åˆ«:' in lines[i]:
                            class_line = lines[i].strip()
                            # æå–ç±»åˆ«åç§°å’ŒID
                            if '(' in class_line and 'ID:' in class_line:
                                class_name = class_line.split('ç±»åˆ«:')[1].split('(')[0].strip()
                                class_id_str = class_line.split('ID:')[1].split(')')[0].strip()
                                device_info['class_name'] = class_name
                                device_info['class_id'] = int(class_id_str)
                            i += 1
                        
                        # è§£æç½®ä¿¡åº¦
                        if i < len(lines) and 'ç½®ä¿¡åº¦:' in lines[i]:
                            conf_line = lines[i].strip()
                            confidence = float(conf_line.split('ç½®ä¿¡åº¦:')[1].strip())
                            device_info['confidence'] = confidence
                            i += 1
                        
                        # è·³è¿‡è¾¹æ¡†åæ ‡æ ‡é¢˜è¡Œ
                        if i < len(lines) and 'è¾¹æ¡†åæ ‡:' in lines[i]:
                            i += 1
                        
                        # è§£æåæ ‡ä¿¡æ¯
                        bbox_coords = {}
                        for _ in range(4):  # è¯»å–4ä¸ªè§’ç‚¹åæ ‡
                            if i < len(lines):
                                coord_line = lines[i].strip()
                                if '(' in coord_line and ')' in coord_line:
                                    # æå–åæ ‡
                                    coord_str = coord_line.split('(')[1].split(')')[0]
                                    x, y = map(float, coord_str.split(','))
                                    if 'å·¦ä¸Šè§’' in coord_line:
                                        bbox_coords['x1'] = x
                                        bbox_coords['y1'] = y
                                    elif 'å³ä¸‹è§’' in coord_line:
                                        bbox_coords['x2'] = x
                                        bbox_coords['y2'] = y
                                i += 1
                        
                        # è§£æä¸­å¿ƒç‚¹åæ ‡
                        if i < len(lines) and 'ä¸­å¿ƒç‚¹åæ ‡:' in lines[i]:
                            center_line = lines[i].strip()
                            if '(' in center_line and ')' in center_line:
                                coord_str = center_line.split('(')[1].split(')')[0]
                                center_x, center_y = map(float, coord_str.split(','))
                                device_info['center_x'] = center_x
                                device_info['center_y'] = center_y
                            i += 1
                        
                        # å¦‚æœè§£æåˆ°äº†æœ‰æ•ˆä¿¡æ¯ï¼Œæ·»åŠ åˆ°åˆ—è¡¨ä¸­
                        if 'class_id' in device_info and 'center_x' in device_info:
                            # è®¾ç½®è¾¹ç•Œæ¡†åæ ‡
                            if 'x1' in bbox_coords and 'x2' in bbox_coords:
                                device_info['bbox'] = [bbox_coords['x1'], bbox_coords['y1'], 
                                                     bbox_coords['x2'], bbox_coords['y2']]
                            else:
                                # å¦‚æœæ²¡æœ‰å®Œæ•´çš„è¾¹ç•Œæ¡†ä¿¡æ¯ï¼Œæ ¹æ®ä¸­å¿ƒç‚¹ä¼°ç®—
                                device_info['bbox'] = [device_info['center_x'] - 50, device_info['center_y'] - 50,
                                                     device_info['center_x'] + 50, device_info['center_y'] + 50]
                            
                            fixed_coordinates.append(device_info)
                    else:
                        i += 1
            
            print(f"âœ“ åŠ è½½å›ºå®šè®¾å¤‡åæ ‡: å…± {len(fixed_coordinates)} ä¸ªè®¾å¤‡")
            for device in fixed_coordinates:
                print(f"  - {device['class_name']} (ID: {device['class_id']}): ä¸­å¿ƒç‚¹ ({device['center_x']:.1f}, {device['center_y']:.1f})")
            
        except Exception as e:
            print(f"è­¦å‘Š: åŠ è½½å›ºå®šè®¾å¤‡åæ ‡å¤±è´¥ {e}")
            
        return fixed_coordinates
        
    def load_chinese_font(self):
        """åŠ è½½ä¸­æ–‡å­—ä½“"""
        try:
            # ä¸­æ–‡å­—ä½“è·¯å¾„
            font_path = os.path.join(self.project_root, self.config['chinese_font_path'])
            if os.path.exists(font_path):
                self.chinese_font = ImageFont.truetype(font_path, 20)
                self.chinese_font_small = ImageFont.truetype(font_path, 16)
                print(f"âœ“ ä¸­æ–‡å­—ä½“åŠ è½½æˆåŠŸ: {font_path}")
            else:
                print(f"è­¦å‘Š: ä¸­æ–‡å­—ä½“æ–‡ä»¶ä¸å­˜åœ¨: {font_path}")
                self.chinese_font = ImageFont.load_default()
                self.chinese_font_small = ImageFont.load_default()
        except Exception as e:
            print(f"è­¦å‘Š: ä¸­æ–‡å­—ä½“åŠ è½½å¤±è´¥ {e}, ä½¿ç”¨é»˜è®¤å­—ä½“")
            self.chinese_font = ImageFont.load_default()
            self.chinese_font_small = ImageFont.load_default()
    
    def draw_chinese_text(self, image, text, position, font, color=(255, 255, 255)):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬
        Args:
            image: OpenCVå›¾åƒ (BGRæ ¼å¼)
            text: è¦ç»˜åˆ¶çš„æ–‡æœ¬
            position: æ–‡æœ¬ä½ç½® (x, y)
            font: PILå­—ä½“å¯¹è±¡
            color: æ–‡æœ¬é¢œè‰² (B, G, R)
        Returns:
            ç»˜åˆ¶äº†æ–‡æœ¬çš„å›¾åƒ
        """
        # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPILå›¾åƒ
        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)
        
        # ç»˜åˆ¶æ–‡æœ¬ (PILä½¿ç”¨RGBæ ¼å¼)
        rgb_color = (color[2], color[1], color[0])  # BGRè½¬RGB
        draw.text(position, text, font=font, fill=rgb_color)
        
        # è½¬æ¢å›OpenCVæ ¼å¼
        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
    def load_models(self):
        """åŠ è½½ç›®æ ‡æ£€æµ‹å’Œå§¿æ€è¯†åˆ«æ¨¡å‹"""
        try:
            # åŠ è½½ç›®æ ‡æ£€æµ‹æ¨¡å‹
            detection_model_path = os.path.join(
                self.project_root, self.config['detection_model_path']
            )
            self.detection_model = YOLO(detection_model_path)
            print(f"âœ“ ç›®æ ‡æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ: {detection_model_path}")
            
            # åŠ è½½å§¿æ€è¯†åˆ«æ¨¡å‹
            pose_model_path = os.path.join(self.project_root, self.config['pose_model_path'])
            self.pose_model = YOLO(pose_model_path)
            print(f"âœ“ å§¿æ€è¯†åˆ«æ¨¡å‹åŠ è½½æˆåŠŸ: {pose_model_path}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def get_hand_keypoints(self, keypoints):
        """
        ä»YOLO poseæ£€æµ‹ç»“æœä¸­æå–æ‰‹éƒ¨å…³é”®ç‚¹
        è¿”å›å·¦å³æ‰‹è…•å’Œæ‰‹è‚˜çš„åæ ‡
        """
        # YOLO poseå…³é”®ç‚¹ç´¢å¼•ï¼ˆCOCOæ ¼å¼ï¼‰- ä»é…ç½®ä¸­è·å–
        keypoint_indices = self.config['keypoint_indices']
        
        hand_points = {}
        
        for point_name, index in keypoint_indices.items():
            if index < len(keypoints):
                x, y, confidence = keypoints[index]
                # å¯ä»¥é€‚å½“è°ƒä½ä¸€ç‚¹ï¼Œè®°å½•åæ ‡
                if confidence > 0.3:
                    hand_points[point_name] = {'x': float(x), 'y': float(y), 'confidence': float(confidence)}
                else:
                    hand_points[point_name] = {'x': None, 'y': None, 'confidence': float(confidence)}
            else:
                hand_points[point_name] = {'x': None, 'y': None, 'confidence': 0.0}
        
        return hand_points
    
    def calculate_center_point(self, points):
        """è®¡ç®—å¤šä¸ªç‚¹çš„ä¸­å¿ƒä½ç½®"""
        valid_points = []
        for point in points:
            if point['x'] is not None and point['y'] is not None:
                valid_points.append((point['x'], point['y']))
        
        if len(valid_points) == 0:
            return {'x': None, 'y': None}
        
        center_x = sum(p[0] for p in valid_points) / len(valid_points)
        center_y = sum(p[1] for p in valid_points) / len(valid_points)
        
        return {'x': float(center_x), 'y': float(center_y)}
    
    def calculate_distance(self, point1, point2):
        """è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»"""
        if (point1['x'] is None or point1['y'] is None or 
            point2['x'] is None or point2['y'] is None):
            return float('inf')
        
        dx = point1['x'] - point2['x']
        dy = point1['y'] - point2['y']
        return math.sqrt(dx * dx + dy * dy)
    
    def detect_objects(self, frame):
        """ä½¿ç”¨ç›®æ ‡æ£€æµ‹æ¨¡å‹æ£€æµ‹è®¾å¤‡"""
        results = self.detection_model(frame)
        detected_objects = []
        detected_device_ids = set()  # è®°å½•å·²æ£€æµ‹åˆ°çš„è®¾å¤‡ID
        
        # è®¾å¤‡ç±»åˆ«æ˜ å°„ï¼ˆä»é…ç½®ä¸­è·å–ï¼‰
        device_mapping = self.config['device_mapping']
        
        # ç¬¬ä¸€æ­¥ï¼šä»æ¨¡å‹æ£€æµ‹ç»“æœä¸­æå–è®¾å¤‡
        for r in results:
            if r.boxes is not None:
                for box in r.boxes:
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    # è®¡ç®—ä¸­å¿ƒç‚¹
                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    
                    # è·å–ç±»åˆ«å’Œç½®ä¿¡åº¦
                    class_id = int(box.cls[0].cpu().numpy())
                    confidence = float(box.conf[0].cpu().numpy())
                    
                    if confidence > 0.3:  # ç½®ä¿¡åº¦é˜ˆå€¼
                        # è¿‡æ»¤æ‰"äºº"ç±»åˆ«ï¼Œå› ä¸ºæˆ‘ä»¬ç”¨å§¿æ€è¯†åˆ«æ¥æ£€æµ‹äººå‘˜
                        if class_id == self.config['person_class_id']:  # ID 3 æ˜¯"äºº"ç±»åˆ«
                            continue
                            
                        class_name = self.device_classes.get(class_id, f"Unknown_{class_id}")
                        if class_name.startswith("Unknown_"):
                            # å°è¯•ä½¿ç”¨æ¨¡å‹çš„nameså±æ€§è·å–åŸå§‹ç±»åˆ«åç§°
                            try:
                                if hasattr(results[0], 'names') and class_id in results[0].names:
                                    original_name = results[0].names[class_id]
                                    # æ£€æŸ¥åŸå§‹åç§°æ˜¯å¦æ˜¯æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡ç±»åˆ«
                                    if original_name in device_mapping:
                                        class_name = device_mapping[original_name]
                                    else:
                                        # å¦‚æœä¸æ˜¯æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡ï¼Œè·³è¿‡
                                        continue
                                elif class_id < len(self.all_classes):
                                    original_name = self.all_classes[class_id]
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡
                                    if original_name in device_mapping:
                                        class_name = device_mapping[original_name]
                                    else:
                                        # å¦‚æœä¸æ˜¯æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡ï¼Œè·³è¿‡
                                        continue
                                else:
                                    # å¦‚æœæ— æ³•è·å–ç±»åˆ«åç§°ï¼Œè·³è¿‡
                                    continue
                            except:
                                # å¦‚æœå‡ºç°å¼‚å¸¸ï¼Œè·³è¿‡
                                continue
                        
                        detected_objects.append({
                            'class_id': class_id,
                            'class_name': class_name,
                            'center': {'x': center_x, 'y': center_y},
                            'bbox': [x1, y1, x2, y2],
                            'confidence': confidence,
                            'source': 'detection'  # æ ‡è®°æ¥æºä¸ºæ£€æµ‹
                        })
                        detected_device_ids.add(class_id)
        
        # ç¬¬äºŒæ­¥ï¼šå¯¹äºæœªæ£€æµ‹åˆ°çš„å…³é”®è®¾å¤‡ï¼Œä½¿ç”¨å›ºå®šåæ ‡
        if self.fixed_device_coordinates:
            # è·å–æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡ç±»åˆ«ID
            target_device_ids = set(self.device_classes.keys())
            missing_device_ids = target_device_ids - detected_device_ids
            
            if missing_device_ids:
                print(f"æ£€æµ‹ç¼ºå¤±è®¾å¤‡ {missing_device_ids}ï¼Œå°è¯•ä½¿ç”¨å›ºå®šåæ ‡è¡¥å……")
                
                for fixed_device in self.fixed_device_coordinates:
                    device_id = fixed_device['class_id']
                    
                    # å¦‚æœè¿™ä¸ªè®¾å¤‡æ²¡æœ‰è¢«æ£€æµ‹åˆ°ä¸”æ˜¯æˆ‘ä»¬å…³å¿ƒçš„è®¾å¤‡
                    if device_id in missing_device_ids:
                        class_name = self.device_classes.get(device_id, f"Unknown_{device_id}")
                        
                        # ä½¿ç”¨å›ºå®šåæ ‡åˆ›å»ºè®¾å¤‡å¯¹è±¡
                        detected_objects.append({
                            'class_id': device_id,
                            'class_name': class_name,
                            'center': {'x': fixed_device['center_x'], 'y': fixed_device['center_y']},
                            'bbox': fixed_device['bbox'],
                            'confidence': 0.5,  # ç»™å›ºå®šåæ ‡ä¸€ä¸ªä¸­ç­‰ç½®ä¿¡åº¦
                            'source': 'fixed_coordinates'  # æ ‡è®°æ¥æºä¸ºå›ºå®šåæ ‡
                        })
                        print(f"  æ·»åŠ å›ºå®šåæ ‡è®¾å¤‡: {class_name} ä¸­å¿ƒç‚¹({fixed_device['center_x']:.1f}, {fixed_device['center_y']:.1f})")
        
        return detected_objects
    
    def detect_poses(self, frame):
        """ä½¿ç”¨å§¿æ€è¯†åˆ«æ¨¡å‹æ£€æµ‹äººä½“å§¿æ€"""
        results = self.pose_model(frame)
        detected_persons = []
        
        for r in results:
            if r.keypoints is not None:
                for i, keypoints in enumerate(r.keypoints.data):
                    # æå–æ‰‹éƒ¨å…³é”®ç‚¹
                    hand_points = self.get_hand_keypoints(keypoints)
                    
                    # è®¡ç®—æ‰‹éƒ¨ä¸­å¿ƒç‚¹ï¼ˆä»…è€ƒè™‘æ‰‹è‚˜å’Œæ‰‹è…•ï¼‰
                    hand_center_points = [
                        hand_points['left_elbow'],
                        hand_points['right_elbow'],
                        hand_points['left_wrist'],
                        hand_points['right_wrist']
                    ]
                    hand_center = self.calculate_center_point(hand_center_points)
                    
                    if hand_center['x'] is not None:  # åªæœ‰å½“èƒ½è®¡ç®—å‡ºæ‰‹éƒ¨ä¸­å¿ƒæ—¶æ‰æ·»åŠ 
                        detected_persons.append({
                            'person_id': i,
                            'hand_keypoints': hand_points,
                            'hand_center': hand_center
                        })
        
        return detected_persons
    
    def analyze_operations(self, persons, objects, frame_number, timestamp):
        """åˆ†æäººå‘˜æ“ä½œè¡Œä¸º"""
        operations = []
        
        for person in persons:
            if person['hand_center']['x'] is None:
                continue
                
            min_distance = float('inf')
            closest_object = None
            
            # æ‰¾åˆ°ç¦»æ‰‹éƒ¨ä¸­å¿ƒæœ€è¿‘çš„ç‰©ä½“
            for obj in objects:
                distance = self.calculate_distance(person['hand_center'], obj['center'])
                if distance < min_distance:
                    min_distance = distance
                    closest_object = obj
            
            # å¦‚æœè·ç¦»å°äºé˜ˆå€¼ï¼Œè®¤ä¸ºæ­£åœ¨æ“ä½œ
            if closest_object and min_distance <= self.operation_threshold:
                operation = {
                    'frame_number': frame_number,
                    'timestamp': timestamp,
                    'person_id': person['person_id'],
                    'device_class_id': closest_object['class_id'],
                    'device_name': closest_object['class_name'],
                    'distance': min_distance,
                    'hand_center': person['hand_center'],
                    'device_center': closest_object['center'],
                    'device_confidence': closest_object['confidence']
                }
                operations.append(operation)
                
                # è®°å½•æ“ä½œå†å²
                self.operation_records[closest_object['class_id']].append(operation)
        
        return operations
    
    def draw_annotations(self, frame, objects, persons, operations):
        """åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœå’Œæ“ä½œåˆ†æ"""
        annotated_frame = frame.copy()
        
        # ç»˜åˆ¶æ£€æµ‹åˆ°çš„ç‰©ä½“
        for obj in objects:
            center_x, center_y = int(obj['center']['x']), int(obj['center']['y'])
            
            # è®¾å¤‡ä¸­å¿ƒç‚¹é¢œè‰²
            center_color = (0, 255, 0)  # ç»¿è‰²
            
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(annotated_frame, (center_x, center_y), 8, center_color, -1)
        
        # ç»˜åˆ¶äººä½“æ‰‹éƒ¨å…³é”®ç‚¹
        hand_colors = self.config['hand_colors']
        
        for person in persons:
            # ç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹
            for point_name, point_data in person['hand_keypoints'].items():
                if point_data['x'] is not None and point_data['y'] is not None:
                    x, y = int(point_data['x']), int(point_data['y'])
                    color = hand_colors.get(point_name, (255, 255, 255))
                    cv2.circle(annotated_frame, (x, y), 6, color, -1)
                    cv2.putText(annotated_frame, point_name[:5], (x+8, y-8), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
            
            # ç»˜åˆ¶æ‰‹éƒ¨ä¸­å¿ƒç‚¹
            if person['hand_center']['x'] is not None:
                center_x = int(person['hand_center']['x'])
                center_y = int(person['hand_center']['y'])
                cv2.circle(annotated_frame, (center_x, center_y), 10, (0, 0, 255), -1)  # çº¢è‰²
                cv2.putText(annotated_frame, f'P{person["person_id"]}', (center_x+12, center_y-12), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        # ç»˜åˆ¶æ“ä½œè¿çº¿å’Œæ ‡æ³¨
        for op in operations:
            hand_x = int(op['hand_center']['x'])
            hand_y = int(op['hand_center']['y'])
            device_x = int(op['device_center']['x'])
            device_y = int(op['device_center']['y'])
            
            # ç»˜åˆ¶è¿çº¿
            cv2.line(annotated_frame, (hand_x, hand_y), (device_x, device_y), (0, 255, 255), 2)
            
            # æ ‡æ³¨æ“ä½œä¿¡æ¯ï¼ˆä½¿ç”¨ä¸­æ–‡å­—ä½“ï¼‰
            mid_x = (hand_x + device_x) // 2
            mid_y = (hand_y + device_y) // 2
            operation_text = f"æ“ä½œä¸­: {op['device_name']}"
            distance_text = f"è·ç¦»: {op['distance']:.1f}px"
            
            # ä½¿ç”¨ä¸­æ–‡å­—ä½“ç»˜åˆ¶æ“ä½œä¿¡æ¯
            annotated_frame = self.draw_chinese_text(
                annotated_frame, operation_text, (mid_x, mid_y-25), self.chinese_font_small, (0, 255, 255)
            )
            annotated_frame = self.draw_chinese_text(
                annotated_frame, distance_text, (mid_x, mid_y+5), self.chinese_font_small, (0, 255, 255)
            )
        
        return annotated_frame
    
    def process_video(self, video_path, output_dir):
        """å¤„ç†è§†é¢‘æ–‡ä»¶"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps} FPS, å…± {total_frames} å¸§")
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        output_video_path = os.path.join(output_dir, 'operation_analysis.mp4')
        out_video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
        
        # æ•°æ®è®°å½•
        all_frame_data = []
        frame_count = 0
        
        print("å¼€å§‹å¤„ç†è§†é¢‘...")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            timestamp = frame_count / fps
            
            if frame_count % 30 == 0:  # æ¯30å¸§æ˜¾ç¤ºè¿›åº¦
                print(f"å¤„ç†è¿›åº¦: {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%)")
            
            # æ£€æµ‹ç‰©ä½“å’Œäººä½“å§¿æ€
            detected_objects = self.detect_objects(frame)
            detected_persons = self.detect_poses(frame)
            
            # åˆ†ææ“ä½œè¡Œä¸º
            operations = self.analyze_operations(detected_persons, detected_objects, frame_count, timestamp)
            
            # ç»˜åˆ¶æ ‡æ³¨
            annotated_frame = self.draw_annotations(frame, detected_objects, detected_persons, operations)
            
            # å†™å…¥è§†é¢‘
            out_video.write(annotated_frame)
            
            # è®°å½•å¸§æ•°æ®
            frame_data = {
                'frame_number': frame_count,
                'timestamp': timestamp,
                'detected_objects': detected_objects,
                'detected_persons': detected_persons,
                'operations': operations
            }
            all_frame_data.append(frame_data)
        
        cap.release()
        out_video.release()
        
        print(f"è§†é¢‘å¤„ç†å®Œæˆï¼å…±å¤„ç† {frame_count} å¸§")
        print(f"æ ‡æ³¨è§†é¢‘ä¿å­˜ä¸º: {output_video_path}")
        
        # ä¿å­˜åˆ†æç»“æœ
        self.save_analysis_results(all_frame_data, output_dir)
        
        return all_frame_data
    
    def save_analysis_results(self, frame_data, output_dir):
        """ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶"""
        
        # 1. è®¡ç®—æ¯ä¸ªè®¾å¤‡çš„æ“ä½œæ—¶é—´ç»Ÿè®¡
        device_operation_stats = self.calculate_operation_time_stats()
        
        stats_df = pd.DataFrame([
            {
                'device_class_id': device_id,
                'device_name': self.device_classes.get(device_id, f"Unknown_{device_id}"),
                'total_operation_frames': stats['total_frames'],
                'total_operation_time_seconds': stats['total_time'],
                'operation_episodes': stats['episodes'],
                'average_distance': stats['avg_distance']
            }
            for device_id, stats in device_operation_stats.items()
        ])
        
        stats_csv_path = os.path.join(output_dir, 'device_operation_stats.csv')
        stats_df.to_csv(stats_csv_path, index=False, encoding='utf-8')
        print(f"è®¾å¤‡æ“ä½œç»Ÿè®¡ä¿å­˜ä¸º: {stats_csv_path}")
        
        # 2. ä¿å­˜å®Œæ•´çš„åˆ†ææŠ¥å‘Š
        report = {
            'analysis_info': {
                'total_frames': len(frame_data),
                'total_duration_seconds': frame_data[-1]['timestamp'] if frame_data else 0,
                'operation_threshold_pixels': self.operation_threshold,
                'device_classes': self.device_classes,
                'analysis_timestamp': datetime.now().isoformat()
            },
            'device_operation_summary': device_operation_stats
        }
        
        report_path = os.path.join(output_dir, 'analysis_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"åˆ†ææŠ¥å‘Šä¿å­˜ä¸º: {report_path}")
        
        # 4. æ‰“å°æ‘˜è¦ä¿¡æ¯
        print("\n" + "="*50)
        print("æ“ä½œåˆ†ææ‘˜è¦")
        print("="*50)
        
        if device_operation_stats:
            print("\nå„è®¾å¤‡æ“ä½œæ—¶é—´ç»Ÿè®¡:")
            for device_id, stats in device_operation_stats.items():
                device_name = self.device_classes.get(device_id, f"Unknown_{device_id}")
                print(f"  {device_name}:")
                print(f"    - æ“ä½œæ—¶é—´: {stats['total_time']:.2f} ç§’")
                print(f"    - æ“ä½œå¸§æ•°: {stats['total_frames']} å¸§")
                print(f"    - æ“ä½œæ¬¡æ•°: {stats['episodes']} æ¬¡")
                print(f"    - å¹³å‡è·ç¦»: {stats['avg_distance']:.2f} åƒç´ ")
        else:
            print("æœªæ£€æµ‹åˆ°ä»»ä½•æ“ä½œè¡Œä¸º")
    
    def calculate_operation_time_stats(self):
        """è®¡ç®—æ¯ä¸ªè®¾å¤‡çš„æ“ä½œæ—¶é—´ç»Ÿè®¡"""
        stats = {}
        
        for device_id, operations in self.operation_records.items():
            if not operations:
                continue
            
            # æŒ‰æ—¶é—´æ’åº
            operations_sorted = sorted(operations, key=lambda x: x['timestamp'])
            
            # è®¡ç®—è¿ç»­æ“ä½œçš„æ—¶é—´æ®µ
            episodes = []
            current_episode = [operations_sorted[0]]
            
            for i in range(1, len(operations_sorted)):
                # å¦‚æœä¸¤ä¸ªæ“ä½œä¹‹é—´çš„æ—¶é—´é—´éš”å°äº2ç§’ï¼Œè®¤ä¸ºæ˜¯è¿ç»­æ“ä½œ
                if operations_sorted[i]['timestamp'] - operations_sorted[i-1]['timestamp'] <= 2.0:
                    current_episode.append(operations_sorted[i])
                else:
                    episodes.append(current_episode)
                    current_episode = [operations_sorted[i]]
            
            episodes.append(current_episode)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            total_frames = len(operations)
            total_time = sum(len(episode) / 30.0 for episode in episodes)  # å‡è®¾30fps
            avg_distance = sum(op['distance'] for op in operations) / len(operations)
            
            stats[device_id] = {
                'total_frames': total_frames,
                'total_time': total_time,
                'episodes': len(episodes),
                'avg_distance': avg_distance
            }
        
        return stats


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®æ‰€æœ‰å›ºå®šå€¼
    config = {
        # æ‰€æœ‰ç±»åˆ«åˆ—è¡¨
        'all_classes': [
            "ä¸€æ¬¡æ€§ç™½å¸ƒ", "ä¸‡ç”¨è¡¨", "ä¸»æ–­è·¯å™¨", "äºº", "å—ç”µå¼“å‡èµ·", "å—ç”µå¼“åˆæ‹¢", "å–‡å­", "å›ºå®šé’³",
            "å·¥å…·æ¡¶", "å·¥å…·ç®±", "æ‰³æ‰‹", "æŠ¹å¸ƒ", "æ¯›åˆ·", "æ¸…æ´å‰‚", "çš®å°º", "ç ç ", "ç ç æŒ‚é’©",
            "çº¢æ ‡ç‰Œ", "è‚¥çš‚æ°´", "è“æ ‡ç‰Œ", "èºä¸åˆ€", "è®°ç§’å™¨", "é¿é›·å™¨", "é’³å­", "é”‰åˆ€",
            "é›†æ²¹æ¡¶", "é©¬å…‹ç¬”", "é«˜å‹ç”µå‹äº’æ„Ÿå™¨", "é«˜å‹ç”µç¼†æ€»æˆ", "é«˜å‹è¿æ¥å™¨", "é«˜å‹éš”ç¦»å¼€å…³"
        ],
        
        # è®¾å¤‡ç±»åˆ«æ˜ å°„
        'device_class_mappings': {
            "ä¸»æ–­è·¯å™¨": "ä¸»æ–­è·¯å™¨æ£€æŸ¥",
            "å—ç”µå¼“åˆæ‹¢": "å—ç”µå¼“æ£€æŸ¥",
            "å—ç”µå¼“å‡èµ·": "å—ç”µå¼“å®éªŒ",
            "é¿é›·å™¨": "é¿é›·å™¨æ£€æŸ¥",
            "é«˜å‹ç”µå‹äº’æ„Ÿå™¨": "é«˜å‹ç”µå‹äº’æ„Ÿå™¨æ£€æŸ¥",
            "é«˜å‹ç”µç¼†æ€»æˆ": "é«˜å‹ç”µç¼†æ€»æˆé¡¶éƒ¨éƒ¨åˆ†æ£€æŸ¥",
            "é«˜å‹è¿æ¥å™¨": "é«˜å‹è¿æ¥å™¨æ£€æŸ¥",
            "é«˜å‹éš”ç¦»å¼€å…³": "é«˜å‹éš”ç¦»å¼€å…³æ£€æŸ¥"
        },
        
        # é»˜è®¤è®¾å¤‡ç±»åˆ«IDæ˜ å°„
        'default_device_classes': {
            2: "ä¸»æ–­è·¯å™¨æ£€æŸ¥",
            4: "å—ç”µå¼“å®éªŒ", 
            5: "å—ç”µå¼“æ£€æŸ¥",
            22: "é¿é›·å™¨æ£€æŸ¥",
            27: "é«˜å‹ç”µå‹äº’æ„Ÿå™¨æ£€æŸ¥",
            28: "é«˜å‹ç”µç¼†æ€»æˆé¡¶éƒ¨éƒ¨åˆ†æ£€æŸ¥",
            29: "é«˜å‹è¿æ¥å™¨æ£€æŸ¥",
            30: "é«˜å‹éš”ç¦»å¼€å…³æ£€æŸ¥"
        },
        
        # æ¨¡å‹è·¯å¾„é…ç½®
        'detection_model_path': 'model/best.pt',
        'pose_model_path': 'model/yolo11l-pose.pt',
        
        # å…³é”®ç‚¹ç´¢å¼•é…ç½®ï¼ˆCOCOæ ¼å¼ï¼‰
        'keypoint_indices': {
            'left_elbow': 7,    # å·¦æ‰‹è‚˜
            'right_elbow': 8,   # å³æ‰‹è‚˜
            'left_wrist': 9,    # å·¦æ‰‹è…•
            'right_wrist': 10   # å³æ‰‹è…•
        },
        
        # è®¾å¤‡ç±»åˆ«æ˜ å°„ï¼ˆç”¨äºæ£€æµ‹ç»“æœå¤„ç†ï¼‰
        'device_mapping': {
            "ä¸»æ–­è·¯å™¨": "ä¸»æ–­è·¯å™¨æ£€æŸ¥",
            "å—ç”µå¼“åˆæ‹¢": "å—ç”µå¼“æ£€æŸ¥", 
            "å—ç”µå¼“å‡èµ·": "å—ç”µå¼“å®éªŒ",
            "é¿é›·å™¨": "é¿é›·å™¨æ£€æŸ¥",
            "é«˜å‹ç”µå‹äº’æ„Ÿå™¨": "é«˜å‹ç”µå‹äº’æ„Ÿå™¨æ£€æŸ¥",
            "é«˜å‹ç”µç¼†æ€»æˆ": "é«˜å‹ç”µç¼†æ€»æˆé¡¶éƒ¨éƒ¨åˆ†æ£€æŸ¥",
            "é«˜å‹è¿æ¥å™¨": "é«˜å‹è¿æ¥å™¨æ£€æŸ¥",
            "é«˜å‹éš”ç¦»å¼€å…³": "é«˜å‹éš”ç¦»å¼€å…³æ£€æŸ¥"
        },
        
        # äººå‘˜ç±»åˆ«ID
        'person_class_id': 3,
        
        # å›ºå®šåæ ‡æ–‡ä»¶è·¯å¾„
        'fixed_coords_file': '../datasets/detection_info_254.txt',
        
        # æ‰‹éƒ¨å…³é”®ç‚¹é¢œè‰²é…ç½®
        'hand_colors': {
            'left_elbow': (255, 0, 0),     # è“è‰²
            'right_elbow': (255, 0, 255),  # æ´‹çº¢è‰²
            'left_wrist': (0, 255, 255),   # é’è‰²
            'right_wrist': (255, 255, 0)   # é»„è‰²
        },
        
        # ä¸­æ–‡å­—ä½“è·¯å¾„é…ç½®
        'chinese_font_path': 'font/SourceHan/OTF/SimplifiedChinese/SourceHanSansSC-Normal.otf'
    }
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    
    parser = argparse.ArgumentParser(description='è®¾å¤‡æ“ä½œæ£€æµ‹åˆ†æç³»ç»Ÿ')
    parser.add_argument('--video', type=str, 
                       default=os.path.join(project_root, 'datasets', 'æµ‹è¯•æ‰€æœ‰åŠ¨ä½œ', 'test01.mp4'),
                       help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str,
                       default=os.path.join(project_root, 'analysis_results'),
                       help='è¾“å‡ºç»“æœç›®å½•è·¯å¾„')
    parser.add_argument('--classes_file', type=str,
                       default=os.path.join(project_root, 'datasets', 'classes.txt'),
                       help='è®¾å¤‡ç±»åˆ«æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--threshold', type=float, default=150.0,
                       help='æ“ä½œåˆ¤æ–­è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.video):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video}")
        return
    
    print("ğŸš€ å¯åŠ¨è®¾å¤‡æ“ä½œæ£€æµ‹åˆ†æç³»ç»Ÿ")
    print(f"ğŸ“¹ è¾“å…¥è§†é¢‘: {args.video}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}")
    print(f"ğŸ“‹ ç±»åˆ«æ–‡ä»¶: {args.classes_file}")
    print(f"ğŸ“ è·ç¦»é˜ˆå€¼: {args.threshold} åƒç´ ")
    
    try:
        # åˆ›å»ºæ£€æµ‹å™¨å®ä¾‹ï¼Œä¼ å…¥é…ç½®
        detector = OperationDetector(project_root, args.classes_file, args.threshold, config)
        
        # å¤„ç†è§†é¢‘
        frame_data = detector.process_video(args.video, args.output)
        
        print("âœ… åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
